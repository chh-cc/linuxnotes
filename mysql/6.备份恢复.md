MySQL使用环境中，基本都会搭建高可用架构最基本的主从，当主库发生故障导致无法使用的时，可以切换从节点提供服务。
那如果：

- 删除操作:DROP TABLE操作 ，在Row模式下，可以通过binlog进行恢复,那再如果DROP DATABASE,那就无法恢复了。
- 在一次迁移升级过程中，bug导致数据库无法启动
- 需要找回前两天的数据
- 云平台全面瘫痪，虽然出现概率很小

这时可以通过之前备份+binglog进行恢复数据。



## 备份工具

物理备份：xtrabackup

逻辑备份：mysqldump（单线程）mysqlpump、mydumper（多线程）

日志备份：mysqlbinlog



逻辑备份与物理备份区别：

逻辑备份

- 备份出来的是sql，**可读性高**
- 压缩比较高，**节省存储空间**
- 依赖数据库引擎，要从磁盘把数据读出来，然后转换为sql，比较耗费资源

物理备份

- 可读性差，性能高
- 压缩比低



1.数据量少于10G以内使用mydumper,mysqldump 进行备份，其他备份建议xtrabackup

2.除了以上场景单表备份，表结构等导出的时候，建议使用逻辑导出。

3.mysqldump是单线程 mydumper是多线程，性能来说mydumper更优。

性能方面：mysqlpump>mydumper>mysqldump 但mysqlpump存在一些bug



## mysqldump

mysqldump 是 MySQL 自带的逻辑备份工具。

它的备份原理是通过协议连接到 MySQL 数据库，将需要备份的数据查询出来，将查询出的数据转换成对应的insert 语句，当我们需要还原这些数据时，只要执行这些 insert 语句，即可将对应的数据还原。



备份命令：

mysqldump [选项] --数据库名 [选项 表名] > 脚本名



全备：

```shell
mysqldump -uroot -pxxx -A > bak/full.sql
```

备份单库或多库：

```shell
mysqldump -uroot -pxxx -B pig pig2 > bak/xxx.sql
```

备份单个或多个表：

```shell
mysqldump -uroot -pxxx 库名 表1 表2 > bak/xxx.sql
#恢复时，必须先存在库
```

特殊参数（必加）：

```shell
-R           #备份存储过程和函数
--triggers   #备份触发器
--master-data=2  #将会输出CHANGE MASTER命令，2的话会默认注释掉；在备份时，会自动记录binlog文件名和位置号
--single-transaction #对innodb进行快照备份,对非innodb表可以实现自动锁表功能
```



恢复思路：

1. 挂出维护界面

2. 找测试库

3. 恢复上一次全备到测试库

4. 截取binlog到误操作时间点，恢复到测试库

   起点：master-data=2，找到备份文件，获取到binlog名字和postition号

   终点：分析最后一个binlog，找到误操作事件的位置

5. 验证数据，将故障表导出，导入到生产库

案例：

```shell
周二23：00全备
mysqldump -uroot -p123 -A -R --triggers --set-gtid-purged=OFF --master-data=2 --single-transaction|gzip > /backup/full_$(date +%F).sql.gz

恢复
准备临时数据库
systemctl start mysqld3307
准备备份
gunzip full_2018-10-17.sql.gz
截取二进制日志
-- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000036', MASTER_LOG_POS=793;
mysqlbinlog --skip-gtids --include-gtids='3ca79ab5-3e4d-11e9-a709-000c293b577e:6-7' /data/binlog/mysql-bin.000036 >/backup/bin.sql
恢复备份到临时库
mysql -S /data/3307/mysql.sock
set sql_log_bin=0;
source /backup/full_2018-10-17.sql
source /backup/bin.sql
将故障表导出并恢复到生产
mysqldump -S /data/3307/mysql.sock db1 t1 >/backup/t1.sql
mysql -uroot -p123 
set sql_log_bin=0
use db1;
source /backup/t1.sql;
```

## mydumper

mysqldump不支持多线程备份，也不支持多线程恢复。如果数据库较大，带来的问题就是备份恢复时间长。
备份出来的文件为一个整体，当需要某个表的数据时，无法从一个整体中取出。

这个时候我们可以考虑使用mydumper来备份数据库，并行备份，并行恢复，可以提升备份恢复速度

备份文件易于管理。备份出来的文件基于表为单位，一个sql文件记录一个表的信息。



早期版本第一步先通过mydumper导出数据，第二步再通过myloader导入数据库

最新版支持stream流式备份恢复，通过管道的方式，一条命令可实现备份和恢复，从而加快恢复速度



mydumper/myloader安装

\# 安装开发工具：
yum install -y cmake gcc gcc-c++ git make
\# 安装GLib，ZLib和PCRE的开发版本：
yum install -y glib2-devel mysql-devel openssl-devel pcre-devel zlib-devel
yum install -y mysql-devel
yum install -y Percona-Server-devel-57
yum install -y mariadb-devel

yum install https://github.com/maxbube/mydumper/releases/download/v0.10.5/mydumper-0.10.5-1.el7.x86_64.rpm



mydumper常用参数

[连接数据库参数]
-h ：待备份数据库主机名或者IP
-u ：待备份数据库用户名
-p ：数据库密码，特别注意，mydumper参数与值需要空格分开
-P ：数据库端口

[备份范围参数]
--database , -B ：dump的数据库
--tables-list , -T ：要备份的表，多个表使用逗号分隔
--threads , -t ：**备份恢复并发线程数**
--regex , -x ：**使用正则表达式去匹配符合条件的数据库和表**
--build-empty-files , -e ：如果表没有数据，则创建空文件
--insert-ignore , -N ：dump行数据通过INSERT IGNORE INTO而不是INSERT INTO
--no-schemas , -m ：不dump表的schema数据，即表的元数据
--no-data , -d ：不dump表的行数据
--triggers , -G ：dump触发器
--events , -E ：dump EVENTS(定时任务)
--routines ，-R ：dump存储过程和函数
--no-views ，-W ：不dump视图
--no-delete：恢复完不删除备份文件



myloader常用参数

--threads , -t ：用于还原数据的线程数，默认为4
--directory , -d ：要还原的mydumper备份目录
--database , -B ：要还原到哪个数据库
--queries-per-transaction , -q ：恢复时多少行提交一次，默认1000行
--overwrite-tables , -o ：**在恢复时，如果表存在，则先删除**
--enable-binlog , -e ：**启用binlog**，这个参数非常重要，如果在主节点进行数据导入，同时同步到从节点，需要开启该参数，默认关闭

### 旧版案例

备份数据库：

-- 导出所有数据库，不包含mysql|test|information_schema|performance_schema|sys。且对trigger(G)、routines(R)、events(E)也导出，进行数据压缩(c)，且8线程(t)导出
mydumper -u root -p 123456 -P 3306 -h 192.168.10.11 --regex '^(?!(mysql|test|information_schema|performance_schema|sys))' -G -R -E -c -t 8 -o /root/backup

-- 备份单个数据库
mydumper -u root -p 123456 -P 3306 -h 192.168.10.11 --database lijiamandb -G -R -E -c -t 8 -o /root/backup

-- 备份lijiamandb和db1数据库，且对trigger(G)、routines(R)、events(E)也导出，且8线程(t)导出
mydumper -u root -p 123456 -P 3306 -h 192.168.10.11 --regex 'lijiamandb|db1' -G -R -E -t 8 -o /root/backup



主要的文件类型有：

metadata ：当前备份到各个主从节点的位点(log、pos)，这对于我们使用基于位点的同步是必要的
{db_name}-schema-create.sql.gz ：创建数据库的SQL
{db_name}-schema-post.sql.gz ：该数据库trigger(G)、routines(R)、events(E)的信息
{db_name}.{table_name}-schema.sql.gz ：表创建SQL
{db_name}.{table_name}.sql.gz ：表数据SQL



详细看一下其中的内容：

（Ⅰ）metadata：记录了主库机器从库的位点信息
Started dump at: 2021-05-23 00:10:15
SHOW MASTER STATUS:
Log: master-bin.000065
Pos: 194
GTID:9d62e676-723d-11ea-83cf-000c29923d50:1-2,
9d6a0a08-723d-11ea-83a1-000c29fb6200:1-920094

SHOW SLAVE STATUS:
Host: 192.168.10.12
Log: master-bin.000014
Pos: 194
GTID:9d62e676-723d-11ea-83cf-000c29923d50:1-2,
9d6a0a08-723d-11ea-83a1-000c29fb6200:1-920094

Finished dump at: 2021-05-23 00:11:08

（Ⅱ）lijiamandb-schema-create.sql ：记录了创建lijiamandb数据库的SQL

CREATE DATABASE /*!32312 IF NOT EXISTS*/ `lijiamandb` /*!40100 DEFAULT CHARACTER SET utf8 */;

（Ⅲ）lijiamandb-schema-post.sql ：记录了函数、过程、EVENT、Trigger等的创建SQL

View Code

（Ⅳ）lijiamandb.t1-schema.sql：记录了表结构创建的SQL

/*!40101 SET NAMES binary*/;
/*!40014 SET FOREIGN_KEY_CHECKS=0*/;

/*!40103 SET TIME_ZONE='+00:00' */;
CREATE TABLE `t1` (
`c1` char(1) NOT NULL,
`c2` char(1) NOT NULL,
`c3` char(1) NOT NULL,
`c4` char(1) NOT NULL,
`c5` char(1) NOT NULL,
KEY `idx_c1234` (`c1`,`c2`,`c3`,`c4`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

（Ⅴ） lijiamandb.t1.sql：记录了t1的行数据
/*!40101 SET NAMES binary*/;
/*!40014 SET FOREIGN_KEY_CHECKS=0*/;
/*!40103 SET TIME_ZONE='+00:00' */;
INSERT INTO `t1` VALUES
("1","1","1","1","1"),
("2","2","2","2","2"),
("3","3","3","3","3"),
("4","4","4","4","4"),
("5","5","5","5","5");



使用myloader还原数据库

myloader -u root -p 123456 -P 3306 -h 192.168.10.11 -e -d /root/backup/ -t 8

### 新版案例

导出远程192.168.1.11数据库上的所有数据（不包括系统库），并导入192.168.1.12数据库里

mydumper -h 192.168.1.11 -u admin -p xxx -P 3306 --rows 10000000 --stream -t 8 -v 3 --regex '^(?!(mysql|sys|performance_schema|information_schema))' --triggers --events --routines --complete-insert --compress -kill-long-queries --no-delete | myloader --stream -o -h 192.168.1.12 -u admin -p xxx -P 3306 -t 8 --enable-binlog

## xtarbackup

安装

1.安装依赖

```sh
wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
yum -y install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL libev-devel
```

2.下载安装

```shell
wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.12/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm
yum -y install percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm
```

备份方式

```ruby
（1）对于非Innodb表（比如 myisam）是，锁表cp数据文件，属于一种温备份。
（2）对于Innodb的表（支持事务的），不锁表，拷贝数据页，最终以数据文件的方式保存下来，把一部分redo和undo一并备走，属于热备方式。
```

### innobackupex使用

全备

```shell
[root@db01 backup]# innobackupex --user=root --password=123  /data/backup
```

自主定制备份路径名

```csharp
[root@db01 backup]# innobackupex --user=root --password=123 --no-timestamp /data/backup/full
```

备份集中多出来的文件：

```ruby
-rw-r----- 1 root root       24 Jun 29 09:59 xtrabackup_binlog_info
-rw-r----- 1 root root      119 Jun 29 09:59 xtrabackup_checkpoints
-rw-r----- 1 root root      489 Jun 29 09:59 xtrabackup_info
-rw-r----- 1 root root     2560 Jun 29 09:59 xtrabackup_logfile

xtrabackup_binlog_info ：（备份时刻的binlog位置）
[root@db01 full]# cat xtrabackup_binlog_info 
mysql-bin.000003    536749
79de40d3-5ff3-11e9-804a-000c2928f5dd:1-7
记录的是备份时刻，binlog的文件名字和当时的结束的position，可以用来作为截取binlog时的起点。

xtrabackup_checkpoints ：
backup_type = full-backuped
from_lsn = 0            上次所到达的LSN号(对于全备就是从0开始,对于增量有别的显示方法)
to_lsn = 160683027      备份开始时间(ckpt)点数据页的LSN    
last_lsn = 160683036    备份结束后，redo日志最终的LSN
compact = 0
recover_binlog_info = 0
（1）备份时刻，立即将已经commit过的，内存中的数据页刷新到磁盘(CKPT).开始备份数据，数据文件的LSN会停留在to_lsn位置。
（2）备份时刻有可能会有其他的数据写入，已备走的数据文件就不会再发生变化了。
（3）在备份过程中，备份软件会一直监控着redo的undo，如果一旦有变化会将日志也一并备走，并记录LSN到last_lsn。
从to_lsn  ----》last_lsn 就是，备份过程中产生的数据变化.
```

全备的恢复

准备备份（Prepared）

```ruby
将redo进行重做，已提交的写到数据文件，未提交的使用undo回滚掉。模拟了CSR的过程
[root@db01 ~]# innobackupex --apply-log  /backup/full
```

恢复备份

```undefined
前提：
1、被恢复的目录是空
2、被恢复的数据库的实例是关闭
systemctl stop mysqld
```

创建新目录

```csharp
[root@db01 backup]# mkdir /data/mysql1
```

数据授权

```kotlin
chown -R mysql.mysql /data/mysql1
```

恢复备份

```ruby
[root@db01 full]# cp -a /backup/full/* /data/mysql1/
```

启动数据库

```kotlin
vim /etc/my.cnf
datadir=/data/mysql1
[root@db01 mysql1]# chown -R mysql.mysql /data/mysql1
systemctl start mysqld
```

innobackupex 增量备份(incremental)

```undefined
（1）增量备份的方式，是基于上一次备份进行增量。
（2）增量备份无法单独恢复。必须基于全备进行恢复。
（3）所有增量必须要按顺序合并到全备中。
```

增量备份命令

```csharp
（1）删掉原来备份
略.
（2）全备（周日）
[root@db01 backup]# innobackupex --user=root --password --no-timestamp /backup/full >&/tmp/xbk_full.log
（3）模拟周一数据变化
db01 [(none)]>create database cs charset utf8;
db01 [(none)]>use cs
db01 [cs]>create table t1 (id int);
db01 [cs]>insert into t1 values(1),(2),(3);
db01 [cs]>commit;

（4）第一次增量备份（周一）
innobackupex --user=root --password=123 --no-timestamp --incremental --incremental-basedir=/backup/full  /backup/inc1 &>/tmp/inc1.log
（5）模拟周二数据
db01 [cs]>create table t2 (id int);
db01 [cs]>insert into t2 values(1),(2),(3);
db01 [cs]>commit;
（6）周二增量
 innobackupex --user=root --password=123 --no-timestamp --incremental --incremental-basedir=/backup/inc1  /backup/inc2  &>/tmp/inc2.log
（7）模拟周三数据变化
db01 [cs]>create table t3 (id int);
db01 [cs]>insert into t3 values(1),(2),(3);
db01 [cs]>commit;
db01 [cs]>drop database cs;
```

恢复到周三误drop之前的数据状态

```undefined
恢复思路：
1.  挂出维护页，停止当天的自动备份脚本
2.  检查备份：周日full+周一inc1+周二inc2，周三的完整二进制日志
3. 进行备份整理（细节），截取关键的二进制日志（从备份——误删除之前）
4. 测试库进行备份恢复及日志恢复
5. 应用进行测试无误，开启业务
6. 此次工作的总结
```

恢复过程

```shell
1. 检查备份
1afe8136-601d-11e9-9022-000c2928f5dd:7-9
2. 备份整理（apply-log）+合并备份（full+inc1+inc2）
(1) 全备的整理
[root@db01 one]# innobackupex --apply-log --redo-only /data/backup/full
(2) 合并inc1到full中
[root@db01 one]# innobackupex --apply-log --redo-only --incremental-dir=/data/backup/inc1 /data/backup/full
(3) 合并inc2到full中
[root@db01 one]# innobackupex --apply-log  --incremental-dir=/data/backup/inc2 /data/backup/full
(4) 最后一次整理全备
[root@db01 backup]#  innobackupex --apply-log  /data/backup/full
3. 截取周二 23:00 到drop 之前的 binlog 
[root@db01 inc2]# mysqlbinlog --skip-gtids --include-gtids='1afe8136-601d-11e9-9022-000c2928f5dd:7-9' /data/binlog/mysql-bin.000009 >/data/backup/binlog.sql
4. 进行恢复
[root@db01 backup]# mkdir /data/mysql/data2 -p
[root@db01 full]# cp -a * /data/mysql/data2
[root@db01 backup]# chown -R mysql.  /data/*
[root@db01 backup]# systemctl stop mysqld
vim /etc/my.cnf
datadir=/data/mysql/data2
systemctl start mysqld
Master [(none)]>set sql_log_bin=0;
Master [(none)]>source /data/backup/binlog.sql
```

## mysqlbinlog工具解析binlog日志实践

mysqlbinlog工具的作用是解析mysql的二进制binlog日志内容，把二进制内容解析成可以在MySQL数据库里执行的SQL语句。

binlog日志作用是用来记录mysql内部增删改等对mysql数据库的记录（对数据库的改动），对数据库查询的语句如show,sdect开头的语句没有记录日志。

**范例一、  利用mysqlbinlog -d参数解析指定库的binlog日志**

```shell
mysqlbinlog -d student /data/3306/mysql-bin.000045|egrep -v "#|--|^$|/\*"
```

按照位置截取，精确

```shell
mysqlbinlog /data/3306/mysql-bin.000045 --start-position=183 --stop-position=304
#注意：起始位置必须精确，停止位置可以不精确
#如果没有指定起始点默认从日志最开始开始，如果没有指定结束点则默认到日志最后。
```

