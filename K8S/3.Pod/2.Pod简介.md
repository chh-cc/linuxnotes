# Pod

## 为什么要用Pod

**容器的本质是进程。**

在linux系统执行pstree -g，可以看到当前系统正在运行的进程树状结构：

```shell

systemd(1)-+-accounts-daemon(1984)-+-{gdbus}(1984)
           | `-{gmain}(1984)
           |-acpid(2044)
          ...      
           |-lxcfs(1936)-+-{lxcfs}(1936)
           | `-{lxcfs}(1936)
           |-mdadm(2135)
           |-ntpd(2358)
           |-polkitd(2128)-+-{gdbus}(2128)
           | `-{gmain}(2128)
           |-rsyslogd(1632)-+-{in:imklog}(1632)
           |  |-{in:imuxsock) S 1(1632)
           | `-{rs:main Q:Reg}(1632)
           |-snapd(1942)-+-{snapd}(1942)
           |  |-{snapd}(1942)
           |  |-{snapd}(1942)
           |  |-{snapd}(1942)
           |  |-{snapd}(1942)
```

比如rsyslogd这个程序，由三个进程组成：一个 imklog 模块，一个 imuxsock 模块，一个 rsyslogd 自己的 main 函数主进程，它们同属于1632进程组。这些进程互相协作，共同完成rsyslogd这个程序的职责。这三个进程必须在同一台机器上运行，否则它们之间的 Socket 通信和文件交换会出现问题。

而**Pod便是一个“进程组”**，解决具有“超亲密关系”的容器的调度问题。

## 什么是Pod

简单点说，Pod是k8s可以创建和部署的最小的单元，Pod包含一个或多个容器

pod其实**是一个逻辑概念**，k8s真正处理的还是宿主机上容器的namespace和cgroups，并不存在一个所谓pod的边界或隔离环境。



pod其实是一组共享了某些资源的容器，这些容器**共享同一个Network Namespace和同一个volume**，它们**借助一个中间容器Infra容器**，Infra 容器一定要占用

极少的资源，所以它使用的是一个非常特殊的镜像，叫作：k8s.gcr.io/pause。这个镜像是一个用汇编语言编写的、永远处于“暂停”状态的容器，解压后的大小也

只有 100~200 KB 左右。

这也就意味着，对于 Pod 里的容器 A 和容器 B 来说（Pod的特性）：

- 它们可以直接使用 **localhost 进行通信**；
- 它们看到的网络设备跟 Infra 容器看到的完全一样；
- 一个 Pod **只有一个 IP 地址**，也就是这个 Pod 的 Network Namespace 对应的 IP 地址；当然，其他的所有网络资源，都是一个 Pod 一份，并且被该 Pod 中的所有容器共享；
- Pod 的生命周期只跟 Infra 容器一致，而与容器 A 和 B 无关。

<img src="D:%5Clinuxnotes%5CK8S%5C2.Pod.assets%5Cimage-20220528004645547.png" alt="image-20220528004645547" style="zoom:67%;" />

把**Pod看成传统环境的“虚拟机”，容器看成运行在这个机器的“用户程序”**，很多关于 Pod 对象的设计就非常容易理解了。

比如，凡是调度、网络、存储，以及安全相关的属性，基本上是 Pod 级别的。

## 创建一个Pod

定义一个静态pod，一般不会这样直接创建pod，因为这样pod**不能自我修复**；用controller可以创建管理多个pod，还提供滚动升级、自愈能力

作为 Kubernetes 项目里最核心的编排对象，Pod 携带的信息非常丰富：

```yaml
vim pod.yaml

apiVersion: v1 #指定api版本，此值必须在kubectl apiversion命令中
kind: Pod #必选，资源类型
metadata: #必选，元数据
  name: nginx #必选，pod名字，在同一个namespace中必须唯一
  namespace: default #可选，pod所在命名空间，不指定默认default，可使用-n指定namespace
  labels: #设定资源的标签，可写多个
    app: nginx
    role: frontend
  annotations:        #可选，自定义注解列表
    app: nginx
spec: #必选，定义pod中容器详细信息
# nodeSelector:     #节点选择
#   zone: node1
  containers:  #必选，容器列表
    - name: nginx #容器的名字
      image: nginx:1.15.2 #容器使用的镜像
      imagePullPolicy: IfNotPresent # 镜像拉取策略
                                    # Always，每次都重新拉取镜像
                                    # Never，每次都不拉取镜像（不管本地是否有）
                                    # IfNotPresent，如果本地有就不拉取，如果没有就拉取
      command:  #容器启动执行的命令，如果不指定则使用打包的启动命令
      - nginx
      - -g
      - "daemon off;"
      args: [string]     #容器启动命令的参数列表
      workingDir: /usr/share/nginx/html #可选，容器的工作目录
      volumeMounts:  #可选，挂载到容器内部的存储配置，可配置多个
      - name: webroot #存储卷名称
        mountPath: /usr/share/nginx/html #挂载目录
        readOnly: True #只读
      ports:  #可选，要暴露的端口号列表
      - containerPort: 80 #端口号
        name: http  #端口名称
        protocol: TCP #端口协议，默认tcp
      env: #可选，容器运行前需要设置的环境变量配置列表
      - name: TZ #变量的名字  
        value: Asia/Shanghai #变量的值 
      - name: LANG
        value: en_US.utf8
#     resources: #可选，资源限制和资源请求限制
#       requests: #容器运行时，最低资源需求，也就是说最少需要多少资源容器才能正常运行
#         cpu: 100m #1000m（微核）=1核
#         memory: 512Mi
#       limits: #最大限制设置
#         cpu: 1000m
#         memory: 1024Mi
#     startupProbe: #可选，检测容器内进程是否完成启动
#       httpGet:
#         path: /api/successStart
#         port: 80
#     readinessProbe:
#       httpGet:
#         path: /
#          port: 80
      livenessProbe: #可选，健康检查
        httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常
          path: / #URI地址
          port: 80
        initialDelaySeconds: 60 #初始化时间
        timeoutSeconds: 2 #检测的超时时间
        periodSeconds: 5  #检查间隔时间
        successThreshold: 1 #检查成功1次表示就绪
        failureThreshold: 2 #检查失败2次表示未就绪
#       exec: 执行命令的方法进行监测，如果其退出码不为0，则认为容器正常
#         command:
#           - cat
#           - /tmp/health
      lifecycle: #生命周期管理
        postStart: #容器创建完成后执行的命令
          exec:
            command:
              - sh
              - -c
              - 'mkdir /data'
        preStop: #容器关闭之前运行的任务
          httpGet:
               path: /
               port: 80
  restartPolicy: Always # 可选，默认Always，容器退出后总是重启该容器
                        # Onfailure：容器异常退出（退出状态码不为0）才会重启容器
                        # Never：不重启
  imagePullSecrets: #可选，拉取镜像使用的secret，可配置多个
  - name: default-dockercfg-86258
  volumes: #共享存储卷列表
  - name: webroot
    emptyDir: {} #挂载目录
```



## Pod相关命令

kubectl自动补齐

```shell
yum -y install bash-completion
bash
source <(kubectl completion bash)
```

创建一个pod

```shell
kubectl apply -f pod.yaml #如果存在则更新，不存在则创建
```

查看pod状态

```shell
kubectl get po [-owide]

NAME                    READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATES
nginx-74cdcc745-c5ctf   2/2     Running   0          38m   172.171.14.193   k8s-node02   <none>           <none>
nginx-74cdcc745-ch9zd   2/2     Running   0          38m   172.161.125.24   k8s-node01   <none>           <none>
nginx-74cdcc745-kr9qh   2/2     Running   0          38m   172.171.14.194   k8s-node02   <none>           <none>

#Pending：Pod的yaml文件已经交给了k8s，API对象已经被创建并保存在etcd中，但这个pod里有些容器因为某些原因不能被顺利创建，比如调度失败。
#Failed：Pod 里至少有一个容器以不正常的状态（非 0 的返回码）退出。这个状态的出现，意味着你得想办法 Debug 这个容器的应用，比如查看 Pod 的 Events 和日志。
#Unknown：意味着 Pod 的状态不能持续地被 kubelet 汇报给 kube-apiserver，这很有可能是主从节点（Master 和 Kubelet）间的通信出现了问题。
#Succeeded：Pod 里的所有容器都正常运行完毕，并且已经退出了。这种情况在运行一次性任务时最为常见。
#Running：这个Pod已经被调度成功，它包含的容器都被成功创建，并且至少有一个在运行。

CrashLoopBackOff： 容器退出，kubelet正在将它重启

InvalidImageName： 无法解析镜像名称

ImageInspectError： 无法校验镜像

ErrImageNeverPull： 策略禁止拉取镜像

ImagePullBackOff： 正在重试拉取

RegistryUnavailable： 连接不到镜像中心

ErrImagePull： 通用的拉取镜像出错

CreateContainerConfigError： 不能创建kubelet使用的容器配置

CreateContainerError： 创建容器失败

m.internalLifecycle.PreStartContainer  执行hook报错

RunContainerError： 启动容器失败

PostStartHookError： 执行hook报错

ContainersNotInitialized： 容器没有初始化完毕

ContainersNotReady： 容器没有准备完毕

ContainerCreating：容器创建中

PodInitializing：pod 初始化中

DockerDaemonNotReady：docker还没有完全启动

NetworkPluginNotReady： 网络插件还没有完全启动

Evicted：即驱赶的意思，意思是当节点出现异常时，kubernetes将有相应的机制驱赶该节点上的Pod。 多见于资源不足时导致的驱赶。
```

进入容器

```shell
kubectl exec -it kubia-66c8b6d4fc-cdzzg -- sh
```

进入pod中指定的容器

```shell
kubectl exec -it <pod-name> -c <container-name> -- bash
```

查看pod标签

```shell
kubectl get po --show-labels

#查看所有namespace
kubectl get po -A --show-labels
```

通过标签筛选pod

```shell
kubectl get po -l app=nginx -w

# -w是动态查看
```

将pod http-label-7cf498876f-rhqxf的标签env由prod更改为debug

```shell
kubectl label pod http-label-7cf498876f-rhqxf env=debug  --overwrite
```

查看命名空间

```shell
kubectl get ns
```

查看指定命名空间的pod

```shell
kubectl get po -n kube-system
#不指定的话默认是default
```

查看pod详细信息，比如**pod状态不是running的时候查看报错**

```shell
kubectl describe po web-2

Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  4m                     default-scheduler  Successfully assigned default/nginx-5cf8b44c6d-hk4l7 to k8s-node02
  Normal   Pulled     2m32s (x5 over 3m59s)  kubelet            Container image "nginx:1.15.2" already present on machine
  Normal   Created    2m32s (x5 over 3m59s)  kubelet            Created container nginx2
  Warning  Failed     2m32s (x5 over 3m59s)  kubelet            Error: failed to start container "nginx2": Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: "sleep 3600": executable file not found in $PATH: unknown
  Warning  BackOff    114s (x10 over 3m57s)  kubelet            Back-off restarting failed container
```

以yaml格式查看pod信息

```shell
kubectl get po web-2 -oyaml
```

查看容器日志，比如**pod状态不是running的时候查看报错**

```shell
kubectl logs -f <pod-name> [<container-name>]
```

如果pod状态为running但没有正常工作，可能是拼写错误，可以通过校验排查

```shell
kubectl apply -validate -f pod.yaml
```

删除pod

```shell
kubectl delete po web-0
```

## Pod常见状态

Pod的status定义在PodStatus对象中，其中有一个phase字段。它简单描述了Pod在其生命周期的阶段。熟悉Pod的各种状态对我们理解如何设置Pod的调度策略、重启策略是很有必要的。下面是 phase 可能的值，也就是pod常见的状态：

- 挂起（Pending）：我们在请求创建pod时，条件不满足，调度没有完成，**没有任何一个节点能满足调度条件**，已经创建了pod但是没有适合它运行的节点叫做挂起，调度没有完成，处于pending的状态会持续一段时间：包括调度Pod的时间和通过网络下载镜像的时间。 
- 运行中（Running）：Pod已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。
- 成功（Succeeded）：Pod 中的所有容器都被成功终止，并且不会再重启。
- 失败（Failed）：Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。
- 未知（Unknown）：未知状态，所谓pod是什么状态是apiserver和运行在pod节点的kubelet进行通信获取状态信息的，如果节点之上的kubelet本身出故障，那么apiserver就连不上kubelet，得不到信息了，就会看Unknown

扩展：还有其他状态，如下：

Evicted状态：出现这种情况，多见于系统内存或硬盘资源不足，可df-h查看docker存储所在目录的资源使用情况，如果百分比大于85%，就要及时清理下资源，尤其是一些大文件、docker镜像。

CrashLoopBackOff：容器曾经启动了，但可能又异常退出了

Error 状态：Pod 启动过程中发生了错误

## Pod创建流程

客户端提交创建pod的请求，apiserver接收到请求后将pod属性信息写入etcd中

apiserver会请求scheduler完成调度，如果调度成功，调度器将node信息给apiserver，apiserver将绑定的node信息写入etcd

部署节点的kubelet会拿到pod信息，然后创建并启动pod中的容器

创建完成后kubelet又将pod状态信息给apiserver，apiserver将pod状态信息写入etcd中

## Pod删除流程

每次部署意味着删除旧pod的同时创建新pod

如果此过程没有正常关闭，可能会出现两个问题：

- 正在处理请求的pod被移除，如果请求不是幂等的，则会导致状态不一致
- k8s将流量路由到已被删除的pod，导致处理请求失败



delete pod两个平行的过程：

- 网络规则：
  - apiserver收到删除pod的请求后，将pod在etcd的状态更新为terminating
  - endpoint controller从endpoint移除该pod的ip
  - kube-proxy检测到endpoint变化更新ipvs规则，不再让流量路由到被删除的pod（不能保证在删除pod前更新网络规则导致问题2）
- 删除pod
  - kubelet在节点清理容器相关资源，如存储、网络
  - kubelet向容器发送SIGTERM；如果容器没有配置，容器立即退出（导致问题1）
  - 如果容器在默认的30秒内没有退出，kubelet将发送SIGKILL强制它退出



解决方法：

- 为容器内进程设置正常关闭

  - 比如spring boot启用优雅关闭

- 添加preStopHook

  - 让kubelet在收到删除pod时sleep一下，留出足够时间来更新网络规则

    ```yaml
    lifecycle:
      preStop:
        exec:
          command: ["sh","-c","sleep 10"]
    ```

- 修改GracePeriodSeconds





## HPA自动扩缩Pod

Horizontal Pod Autoscaler：Pod的水平自动伸缩器

观察**Pod的CPU、内存使用率**来自动扩缩Pod数量

不适用无法缩放的对象，比如DaemonSet

必须定义requests参数，必须安装metrics-server

运行hpa资源，名称为demo-nginx，当deployment资源对象的cpu使用率达到百分之20就进行扩容，最小2个，最多5个

```shell
kubectl autoscale deploy demo-nginx --cpu-percent=20 --min=2 --max=5
```

模拟并发请求

```shell
[root@node01 ~]# while true; do wget -q -O- 10.97.45.108; done              #一直返回ok属于正常现象
```

查看hpa资源对cpu的占用情况

```shell
kubectl get hpa
kubectl get top
```

## 修改pod数量

k8s默认每个节点最多创建110个pod

修改pod数量：

在启动命令尾部添加变量 $KUBELET_NODE_MAX_PODS 

```shell
vim /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
添加：
	Environment="KUBELET_NODE_MAX_PODS=--max-pods=600"
	ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS $KUBELET_NODE_MAX_PODS
	
systemctl daemon-reload
systemctl restart kubelet
```

## Pod安全上下文

K8s对Pod和容器提供的安全机制，可以设置Pod特权和访问控制。



设置容器以普通用户运行

- Dockerfile里使用USER指定运行用户
- K8s里指定spec.securityContext.runAsUser，指定容器默认用户UID在这里只能指定ID，不能指定用户名了

```yaml
spec:
  securityContext:
    runAsUser: 1000  # 镜像里必须有这个用户UID
    fsGroup: 1000    # 数据卷挂载后的目录属组设置为该组
```



容器中有些应用程序可能需要访问宿主机设备、修改内核等需求，在默认情况下， 容器没这个有这个能力，因此这时会考虑给容器设置特权模式。

```yaml

containers:
- image: lizhenliang/flask-demo:root
  name: web
  securityContext:
    privileged: true
```

