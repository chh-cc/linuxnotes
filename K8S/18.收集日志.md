# 收集日志

k8s收集日志区别于传统日志收集：

- 节点不固定
- 重启服务会漂移
- 需关注stdout、stderr

所以说，Kubernetes 的日志系统在设计的时候，必须得**独立于节点和 Pod 的生命周期**，且保证日志数据可以实时采集到服务端，即完全独立于 Kubernetes 系统，使用自己的后端存储和查询工具

## 几种收集日志架构

1. 直接在应用程序中将日志信息推送到采集后端

2. 在节点上运行一个 Agent 来采集节点级别的日志

   在每一个 Kubernetes Node 上都部署一个 Agent，该 Agent 负责对该节点上运行的所有容器进行日志收集，并推送到后端的日志存储系统里。这个 Agent 通常需要可以访问到宿主机上的指定目录，比如`/var/lib/docker/containers/`

3. 在应用的 Pod 内使用一个 Sidecar 容器来收集应用日志

## 日志采集场景

**集群核心组件日志：**
审计需要Kube-apiserver日志，诊断调度需要kube-[scheduler](https://so.csdn.net/so/search?q=scheduler&spm=1001.2101.3001.7020)日志，接入层流量分析需要Ingress日志。（一部分为k8s控制面板组件，还有一些核心的中间件，比如ingress）

**主机内核日志：**

内核日志可以用于帮助开发及运维同学诊断影响节点稳定的异常，如：文件系统异常，网络栈异常，设备驱动异常等。

**应用运行时日志：**

docker是最常见的容器运行时，可以利用Docker和Kubelet日志排查Pod创建和启动失败等问题。

**业务应用日志：**

通过分析业务的运行日志分析和观察业务状态，诊断异常。



## filebeat收集标准输出日志

## filebeat部署

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
  namespace: ops
  labels:
    k8s-app: filebeat
data:
  filebeat.yml: |-
    filebeat.config:
      inputs:
        # Mounted `filebeat-inputs` configmap:
        path: ${path.config}/inputs.d/*.yml
        # Reload inputs configs as they change:
        reload.enabled: false
      modules:
        path: ${path.config}/modules.d/*.yml
        # Reload module configs as they change:
        reload.enabled: false
 
    output.elasticsearch:
      hosts: ['elasticsearch.ops:9200']
---
#下面是针对k8s的配置，日志类型为docker。这里要启动filebeat内置对docker的支持基于docker采集日志，并且对日志进行处理
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-inputs
  namespace: ops
  labels:
    k8s-app: filebeat
data:
  kubernetes.yml: |-
    - type: docker
      containers.ids:
      - "*"
      processors:
        - add_kubernetes_metadata:
            in_cluster: true
---
apiVersion: apps/v1 
kind: DaemonSet
metadata:
  name: filebeat
  namespace: ops
  labels:
    k8s-app: filebeat
spec:
  selector:
    matchLabels:
      k8s-app: filebeat
  template:
    metadata:
      labels:
        k8s-app: filebeat
    spec:
      serviceAccountName: filebeat
      terminationGracePeriodSeconds: 30
      containers:
      - name: filebeat
        image: elastic/filebeat:7.9.2
        args: [
          "-c", "/etc/filebeat.yml",
          "-e",
        ]
        securityContext:
          runAsUser: 0
          # If using Red Hat OpenShift uncomment this:
          #privileged: true
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 100Mi
        volumeMounts:
        - name: config
          mountPath: /etc/filebeat.yml
          readOnly: true
          subPath: filebeat.yml
        - name: inputs
          mountPath: /usr/share/filebeat/inputs.d
          readOnly: true
        - name: data
          mountPath: /usr/share/filebeat/data
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: config
        configMap:
          defaultMode: 0600
          name: filebeat-config
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: inputs
        configMap:
          defaultMode: 0600
          name: filebeat-inputs
      # data folder stores a registry of read status for all files, so we don't send everything again on a Filebeat pod restart
      - name: data
        hostPath:
          path: /var/lib/filebeat-data
          type: DirectoryOrCreate
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: filebeat
subjects:
- kind: ServiceAccount
  name: filebeat
  namespace: ops
roleRef:
  kind: ClusterRole
  name: filebeat
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: filebeat
  labels:
    k8s-app: filebeat
rules:
- apiGroups: [""] # "" indicates the core API group
  resources:
  - namespaces
  - pods
  verbs:
  - get
  - watch
  - list
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: filebeat
  namespace: ops
  labels:
    k8s-app: filebeat
```

