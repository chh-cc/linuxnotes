# RDS

数据库性能对比

|              | MySQL | Redis      | MongoDB       |
| ------------ | ----- | ---------- | ------------- |
| 单表存储极限 | 1亿   | 无限制     | 10亿~海量数据 |
| QPS          | 2~5万 | 10W~高并发 | 1W~高并发     |

80%数据库性能问题出在sql语句上

80%的sql语句性能问题由索引引起

- RDS MySQL仅支持InnoDB和X-Engine两种存储引擎
- 对外提供服务端口取值范围为3200~3999
- 5.7高可用版本
  - ssd云盘/essd云盘：不能迁移可用区、修改复制方式、升级三节点版本、下载备份、跨地域备份、单库单表恢复
  - 本地ssd盘：不能自动扩容、

## 创建实例

**系列：**

![image-20210309102039589](https://gitee.com/c_honghui/picture/raw/master/img/20210309102039.png)

● 基础版：单节点运行，无 SLA 保证，产品功能较少，并且执行变更配置、版本升级等任务时，会出现较长时间的不可用
● 高可用：**主从 (1 主 1 从 ) 双节点**运行，推荐购买，其中**从库是隐藏的高可用节点，不提供服务**，如果需要读写分离，需要购买只读实例，具体会在“只读实例”进行说明。
● 三节点企业版：1 主 2 从三节点运行的版本

**存储类型：**

RDS 存储数据的磁盘类型，  推荐购买优先级为 : **本地 SSD 高可用** -> 云 SSD 高可用 -> 单机基础版：  

● 本地 SSD 将**数据存储于本地SSD盘**，可以降低I/O延时。。
● SSD 云盘将数据存储于SSD云盘，即实现了**计算与存储分离**。
● ESSD 云盘是增强型（Enhanced）的 SSD 云盘，增强的原因是 ESSD 采用了 25 GE 网络和 RDMA 技术，读写能力更强和延迟更低。
● 请注意，从性能来说，ESSD 云盘无疑是更适合数据库的，但是 ESSD 云盘数据库由于推出较晚，相比本地 SSD 盘实例来说，**功能不如本地 SSD 丰富**，比如云 SSD 实例磁盘满后不支持临时解锁。  

**部署方案：**

![image-20210309112419334](https://gitee.com/c_honghui/picture/raw/master/img/20210309112524.png)

当选择了主节点可用区后，如果选择的系列是高可用版，还需要选择部署方案，部署方案分为单可用区部署与多可用区部署，如果要实现同城容灾的话，可以考虑多可用区部署，即主节点和备节点不在同一个可用区。备节点可用区目前只能自动分配。  

**实例规格：**

通用型：与同一服务器上的其他通用型实例共享CPU和存储资源。

独享型**（企业级）**：独享或独占型的实例规格

**表名大小写：**

![image-20210309112846662](https://gitee.com/c_honghui/picture/raw/master/img/20210309112846.png)

如果您的业务表是区分大小写的，需要在此处选择“区分大小写”，创建完成后，不支持修改。  

**小版本升级策略：**

![image-20210309112900361](https://gitee.com/c_honghui/picture/raw/master/img/20210309112900.png)

● 勾选自动升级，有新的内核小版本发布时，将在待处理事件里展示出来，并在选定时间内进行升级。
● 勾选手动升级，也并不意味着一直不会升级，当小版本的生命周期结束的时候，依然会强制升级 ( 同样将会在待处理事件里展示出来 )。
● 阿里云后台系统会在一些极端情况下进行小版本升级，这类小版本升级一般不会做短信或者站内信通知，也不会在待处理事件展示。  

## 设置IP白名单

创建RDS MySQL实例后，暂时还无法访问该实例，需要设置白名单

1. 左侧导航栏单击**数据安全性**。
2. 单击**添加白名单分组**，填写**分组名称**；或单击已有分组的 **修改** 。
3. 填写需要访问该实例的IP地址或IP段，可加载ecs内网IP

## 设置安全组

创建RDS MySQL实例后，暂时无法访问实例。您需要设置RDS MySQL实例的IP白名单或安全组。

在RDS白名单中添加安全组后，该安全组中的ECS实例就可以访问RDS实例。

## 创建数据库和账号

RDS MySQL不提供Super权限，RDS MySQL实例支持两种数据库账号：高权限账号和普通账号。

| 账号类型     | 建库数量 | 建表数量 | 用户数             |
| :----------- | :------- | :------- | :----------------- |
| 高权限账号   | 不限     | <20万    | 与实例内核参数相关 |
| 普通权限账号 | 500      | <20万    | 与实例内核参数相关 |

### 创建高权限账号

只能通过控制台或API创建和管理。一个实例中**只能创建一个高权限账号**，可以管理所有普通账号和数据库。

### 创建普通帐号

可以通过控制台、API或者SQL语句创建和管理。需要手动给普通账号授予特定数据库的权限。普通账号不能创建和管理其他账号，也不能断开其他账号的连接。

### 创建数据库

步骤：

给数据库授权账号

选择授予账号的权限：**读写**、**只读**、**仅DDL**或**仅DML**

账号权限列表：

高权限账号：SELECT  INSERT  UPDATE  DELETE  CREATE  DROP  RELOAD  PROCESS  REFERENCES  INDEX      ALTER  CREATE TEMPORARY TABLES  LOCK TABLES  EXECUTE  REPLICATION SLAVE      REPLICATION CLIENT  CREATE VIEW  SHOW VIEW  CREATE ROUTINE  ALTER ROUTINE      CREATE USER  EVENT  TRIGGER    

普通帐号：

- 只读：SELECT  LOCK TABLES  SHOW VIEW  PROCESS  REPLICATION SLAVE  REPLICATION CLIENT    
- 读写：SELECT  INSERT  UPDATE  DELETE  CREATE    DROP  REFERENCES  INDEX  ALTER  CREATE TEMPORARY TABLES      LOCK TABLES  EXECUTE  CREATE VIEW  SHOW VIEW  CREATE ROUTINE      ALTER ROUTINE  EVENT  TRIGGER  PROCESS  REPLICATION SLAVE      REPLICATION CLIENT
- ddl：CREATE  DROP  INDEX  ALTER  CREATE TEMPORARY TABLES    LOCK TABLES  CREATE VIEW  SHOW VIEW  CREATE ROUTINE  ALTER ROUTINE      PROCESS  REPLICATION SLAVE  REPLICATION CLIENT
- dml：SELECT  INSERT  UPDATE  DELETE  CREATE TEMPORARY TABLES    LOCK TABLES  EXECUTE  SHOW VIEW  EVENT  TRIGGER      PROCESS  REPLICATION SLAVE  REPLICATION CLIENT  

## 连接实例

默认提供内网地址供您内部访问RDS实例，如果需要外网访问，您需要申请外网地址。

高安全模式下才能同时使用内网地址和外网地址

```shell
mysql -hrm-bp1457xxxxxx.mysql.rds.aliyuncs.com -P3306 -utestuser -p [-D 数据库名]
```

## 变更实例

### 自动或手动主备切换

实例默认为自动切换，当主实例出现故障无法访问时，会自动切换到备实例。

- 主备实例切换过程中**可能会有闪断**，请确保您的应用程序具有自动重连机制。
- 如果实例下挂载有只读实例，那么主备实例切换后，**只读实例的数据会有几分钟的延迟**，因为需要重建复制链路、同步增量数据等。
- 在主备实例切换期间，**有很多操作无法执行**，例如管理数据库和账号、切换网络类型等，建议您选择**可维护时间内进行切换**。

#### 手动切换主备

2. 在左侧导航栏中，选择**服务可用性**。
3. 在**实例可用性**区域，单击**主备库切换**。
4. 选择切换时间，然后单击**确定**。
4. 可以在实例的**日志管理**页面查看**主备切换日志**。

#### 临时关闭自动主备切换：

- 大促活动等，不希望主备切换影响系统可用性。
- 重要应用系统升级等，不希望主备切换引进其他变数。
- 重大事件或者稳定保障期，不希望主备切换影响系统稳定性。

1. 单击**主备库切换设置**。
2. 选择**临时关闭**，并设置**临时关闭截止时间：**，然后单击**确定**。

### 设置可维护阶段

为保障云数据库RDS实例的稳定性，后端系统会不定期对实例进行维护操作。默认可维护时间段为02:00~06:00，您可以根据业务规律，将可维护时间段**设置在业务低峰期**，以免维护过程中可能对业务造成的影响。

- 在进行正式维护前，RDS会给阿里云账号中设置的联系人发送短信和邮件，请注意查收。
- 实例维护当天，为保障整个维护过程的稳定性，实例会在可维护时间段时将实例状态切换为**实例维护中**。当实例处于该状态时，对数据库的访问以及查询类操作（如性能监控）不会受到任何影响，但除了账号管理、数据库管理和IP白名单设置外的变更操作（如升降级、重启等）均暂时无法使用。
- 在可维护时间段内，实例会发生1到2次连接闪断，请确保应用程序具有重连机制。

### 修改数据复制方式

前提：

- MySQL 8.0高可用版（本地SSD盘）
- MySQL 5.7高可用版（本地SSD盘）
- MySQL 5.6高可用版
- MySQL 5.5

复制方式：

- 强同步
  - 应用发起的更新在主实例执行完成后，会将日志同步传输到所有备实例，至少1个备实例收到并存储日志后，事务才完成提交。
  - 在强同步模式下，实例的复制方式会始终保持强同步，无论出现何种状况，都不会退化为异步。
  - 当实例的**节点数≥3时**，才支持强同步。因此，只有三节点企业版（原金融版）实例支持强同步。三节点企业版实例的数据复制方式无法修改。

- 半同步

  应用发起的更新在主实例执行完成后，会将日志同步传输到备实例，**备实例收到日志**，事务就算完成了提交，不需要等待备实例执行日志内容。

  当备实例不可用或者主备实例间出现网络异常时，半同步会退化为异步。

- 异步

  应用发起更新请求，即进行增加、删除、修改数据的操作时，**主实例完成操作**后会立即响应应用，同时主实例向备实例异步复制数据。因此，在异步数据复制方式下，备实例不可用时不会影响主实例上的操作，而主实例不可用时可能会导致主备实例数据不一致。

操作：

1. 在左侧导航栏中，单击**服务可用性**。
2. 单击**修改数据复制方式**。

## 实例参数

为保证实例的稳定，仅支持对控制台中开放的参数进行修改

### 修改单个参数

部分参数修改后不需要重启实例，通常5分钟左右可以生效；部分参数修改后需要重启实例

### 使用参数模板

如果需要批量管理实例的参数，您可以使用参数模板功能，快速应用模板到实例上。

高可用版和基础版提供三种系统参数模板：

- 默认参数模版

  数据安全性最高，但速度较慢。数据复制方式为半同步，涉及数据保护的参数为：

  - InnoDB引擎

    - innodb_flush_log_at_trx_commit = 1
    - sync_binlog = 1

  - X-Engine引擎（当前仅提供默认参数模板）

    sync_binlog = 1

- 异步参数模版

  数据安全性较高，速度较快。数据复制方式为异步，涉及数据保护的参数为：

  - innodb_flush_log_at_trx_commit = 1
  - sync_binlog = 1

- 高性能参数模版

  数据安全性一般，但速度最快。数据复制方式为异步，涉及数据保护的参数为：

  - innodb_flush_log_at_trx_commit = 2
  - sync_binlog = 1000

| 参数                           | 取值 | 说明                                                         |
| :----------------------------- | :--- | :----------------------------------------------------------- |
| innodb_flush_log_at_trx_commit | 1    | 事务提交时，把事务日志从缓存区写到日志文件中，并且立刻写入到磁盘上。 |
|                                | 2    | 事务提交时，把事务日志从缓存区写到日志文件中，但不一定立刻写入到磁盘上。日志文件会每秒写入到磁盘，如果写入前系统崩溃，就会导致最后1秒的日志丢失。 |
| sync_binlog                    | 1    | 事务提交后，将二进制日志文件写入磁盘并立即刷新，相当于同步写入磁盘，不经过系统缓存。 |
|                                | 1000 | 每写入1000次系统缓存就执行一次写入磁盘并刷新的操作，会有数据丢失的风险。 |

### 重要参数调优

修改参数步骤：找到参数进行修改→点击提交参数

**innodb_buffer_pool_size**

当前仅支持通过公式进行修改。公式如下：

```
{DBInstanceClassMemory * X / Y}    

DBInstanceClassMemory为RDS实例规格内存系统变量。
X、Y为分子和分母
可调整范围为：[128MB, DBInstanceClassMemory * 8 / 10]，即最小调整到128 MB，最大调整到RDS实例规格内存的80%。
```

如果`RDS云盘实例规格内存 < 64 GB`，默认`InnoDB Buffer Pool = (RDS实例规格内存 - RDS系统预留内存) * 0.7`。

如果`RDS云盘实例规格内存 ≥ 64 GB`，或RDS实例为本地SSD盘，默认`InnoDB Buffer Pool = RDS实例规格内存 * 0.7`。

**back_log**

- 适用版本：8.0、5.7、5.6、5.5

- 默认值：3000

- 修改完后是否需要重启：是

- 作用：MySQL每处理一个连接请求时都会创建一个新线程与之对应。在主线程创建新线程期间，如果前端应用有大量的短连接请求到达数据库，MySQL会**限制这些新的连接进入请求队列**，由参数back_log控制。如果**等待的连接数量**超过back_log的值，则将不会接受新的连接请求，所以如果需要MySQL能够处理大量的短连接，需要提高此参数的大小。

- 现象：如果参数过小，应用可能出现如下错误：

  ```
  SQLSTATE[HY000] [2002] Connection timed out;
  ```

- 修改建议：提高此参数值的大小。

**innodb_autoinc_lock_mode**

- 适用版本：8.0、5.7、5.6、5.5

- 默认值：1

- 修改完后是否需要重启：是

- 作用：在MySQL 5.1.22后，InnoDB为了解决自增主键锁表的问题，引入了参数innodb_autoinc_lock_mode，用于控制自增主键的锁机制。该参数可以设置的值为0、1、2，RDS默认的参数值为1，表示InnoDB使用轻量级别的mutex锁来获取自增锁，替代最原始的表级锁。但是在load data（包括`INSERT … SELECT`和`REPLACE … SELECT`）场景下若使用自增表锁，则可能导致应用在并发导入数据时出现死锁。

- 现象：在load data（包括INSERT … SELECT和REPLACE … SELECT）场景下若使用自增表锁，在并发导入数据时出现如下死锁：

  ```
  RECORD LOCKS space id xx page no xx n bits xx index PRIMARY of table xx.xx trx id xxx lock_mode X insert intention waiting. TABLE LOCK table xxx.xxx trx id xxxx lock mode AUTO-INC waiting；
  ```

- 修改建议：建议将该参数值改为2，表示**所有情况插入都使用轻量级别的mutex锁**（**只针对row模式**），这样就可以避免auto_inc的死锁，同时在`INSERT … SELECT`的场景下性能会有很大提升。

**query_cache_size**

- 适用版本：5.7、5.6、5.5
- 默认值：3145728
- 修改完后是否需要重启：否
- 作用：该参数用于控制**MySQL query cache的内存大小**。如果MySQL开启query cache，在执行每一个query的时候会先锁住query cache，然后判断是否存在于query cache中，如果存在则直接返回结果，如果不存在，则再进行引擎查询等操作。同时，insert、update和delete这样的操作都会将query cahce失效掉，这种失效还包括结构或者索引的任何变化。但是**cache失效的维护代价较高，会给MySQL带来较大的压力**。所以，当数据库不会频繁更新时，query cache是很有用的，但如果写入操作非常频繁并集中在某几张表上，那么query cache lock的锁机制就会造成很频繁的锁冲突，对于这一张表的写和读会互相等待query cache lock解锁，从而导致select的查询效率下降。
- 现象：数据库中有大量的连接状态为`checking query cache for query`、`Waiting for query cache lock`、`storing result in query cache`。
- 修改建议：RDS默认是关闭query cache功能的，如果您的实例打开了query cache，当出现上述情况后可以关闭query cache。

**net_write_timeout**

- 适用版本：8.0、5.7、5.6、5.5

- 默认值：60

- 修改完后是否需要重启：否

- 作用：**等待将一个block发送给客户端的超时时间**。

- 现象：若参数设置过小，可能会导致客户端出现如下错误：

  ```
  the last packet successfully received from the server was milliseconds ago或the last packet sent successfully to the server was milliseconds ago.
  ```

- 修改建议：该参数在RDS中默认设置为60秒，一般在网络条件比较差时或者客户端处理每个block耗时较长时，由于net_write_timeout设置过小导致的连接中断很容易发生，建议增加该参数的大小。

**tmp_table_size**

- 适用版本：8.0、5.7、5.6、5.5
- 默认值：2097152
- 修改完后是否需要重启：否
- 作用：该参数用于决定内部**内存临时表的最大值**，每个线程都要分配，实际起限制作用的是tmp_table_size和max_heap_table_size的最小值。如果内存临时表超出了限制，MySQL就会自动地把它转化为基于磁盘的MyISAM表。优化查询语句的时候，要避免使用临时表，如果实在避免不了的话，要保证这些临时表是存在内存中的。
- 现象：如果复杂的SQL语句中包含了group by、distinct等不能通过索引进行优化而使用了临时表，则会导致SQL执行时间加长。
- 修改建议：如果应用中有很多group by、distinct等语句，同时数据库有足够的内存，可以增大tmp_table_size（max_heap_table_size）的值，以此来提升查询性能。

loose_rds_max_tmp_disk_space

- 适用版本：5.6、5.5

- 默认值：10737418240

- 修改完后是否需要重启：否

- 作用：用于控制MySQL能够使用的临时文件的大小。

- 现象：如果临时文件超出loose_rds_max_tmp_disk_space的取值，则会导致应用出现如下错误：

  ```
  The table ‘/home/mysql/dataxxx/tmp/#sql_2db3_1’ is full
  ```

- 修改建议：首先需要分析一下导致临时文件增加的SQL语句是否能够通过索引或者其它方式进行优化。其次，如果确定实例的空间足够，则可以提升此参数的值，以保证SQL能够正常执行。

loose_tokudb_buffer_pool_ratio

- 适用版本：5.6
- 默认值：0
- 修改完后是否需要重启：是
- 作用：用于控制TokuDB引擎能够使用的buffer内存大小，比如innodb_buffer_pool_size设置为1000MB，tokudb_buffer_pool_ratio设置为50（代表50%），那么TokuDB引擎的表能够使用的buffer内存大小则为500MB。
- 修改建议：如果RDS中使用TokuDB引擎，建议调大该参数，以此来提升TokuDB引擎表的访问性能。

loose_max_statement_time

- 适用版本：5.6

- 默认值：0

- 修改完后是否需要重启：否

- 作用：用于控制查询在MySQL的最长执行时间。如果超过该参数设置的时间，查询将会自动失败，默认是不限制。

- 现象：若查询时间超过了该参数的值，则会出现如下错误：

  ```
  ERROR 3006 (HY000): Query execution was interrupted, max_statement_time exceeded
  ```

- 修改建议：如果您想要控制数据库中SQL的执行时间，则可以开启该参数，单位是毫秒。

**loose_rds_threads_running_high_watermark**

- 适用版本：5.6、5.5
- 默认值：50000
- 修改完后是否需要重启：否
- 作用：用于控制MySQL并发的查询数目，比如将rds_threads_running_high_watermark的值设置为100，则允许MySQL同时进行的并发查询为100个，超过限制数量的查询将会被拒绝掉。
- 修改建议：该参数常常在秒杀或者大并发的场景下使用，对数据库具有较好的保护作用。

## 备份

[高可用版](https://help.aliyun.com/document_detail/127875.htm#concept-1443745)和[三节点企业版](https://help.aliyun.com/document_detail/51701.htm#concept-yqy-zvw-5db)实例：备份在备实例执行，不占用主实例CPU，不影响主实例性能。

可使用命令行或图形界面进行逻辑数据备份。仅限通过 RDS 管理控制台 或 OPEN API 进行物理备份。

### 备份的组成

- **数据备份**：系统对数据进行备份，并生成备份集。您可以恢复备份集所在时间点的数据。
- **日志备份**：开启日志备份后，基于“数据备份+日志备份”，您可以恢复时间范围内**任意时间点**的数据。

### 备份空间

- 数据备份和日志备份存放于阿里云提供的备份空间，**不占用实例的存储空间**。
- 日志分为本地日志和日志备份。
  - 本地日志占用实例空间，不涉及费用
  - 开启日志备份后本地日志会上传到备份空间，需要费用
- 云盘实例采用快照备份。**快照备份的大小可能远大于数据的大小**

### 自动备份与手动备份

- 只读实例不支持备份设置。
- 备份期间不要执行DDL操作，避免锁表导致备份失败。
- 尽量选择业务低峰期进行备份。
- 表数量超过60万将无法进行备份。表数量过多时建议进行分库。
- 备份的表数量超过5万张将无法进行单库单表恢复。

#### 自动备份

数据备份无法关闭，您可以修改数据备份的频率。日志备份可以关闭

备份设置：

2. 单击**备份恢复**
3. 选择**备份设置**页签，单击**编辑**

数据备份设置：

| 实例类型       | 参数             | 说明                                                         |
| :------------- | :--------------- | :----------------------------------------------------------- |
| **所有实例**   | **备份周期**     | 每周至少选2天进行数据备份。                                  |
|                | **保留时长**     | 默认为7天。可选范围：<br />云盘版：7~730天。<br />**说明**<br />保留不超过730天的数据备份为常规备份。<br />保留超过730天的数据备份为归档备份，费用较低。<br />**说明** 如果设置超过730天，或者勾选**实例释放前长期保留**，则还需设置归档备份的保留个数，例如保留每个月最早的2个归档备份。 |
| **本地盘实例** | **库表备份**     | 开启后将支持[MySQL单库单表恢复](https://help.aliyun.com/document_detail/103175.htm#concept-ocr-swk-ngb)。默认为开启，无法关闭。<br />**说明**<br />仅RDS MySQL 8.0、5.7、5.6 高可用版（本地盘）支持。<br />开启后，新生成的备份文件将逐步采用新的备份格式。 |
| **云盘实例**   | **增加快照频率** | 勾选后，可设置每N小时备份1次，甚至每15分钟备份一次。<br />**说明**<br />仅高可用云盘版支持。<br />**增加快照频率**和**秒级备份**不能同时开启。<br />开启后，最大保留时长会减少。 |
|                | **秒级备份**     | 开启后，每次备份只需1秒即可完成。<br />**说明**<br />仅高可用ESSD云盘版支持。<br />**增加快照频率**和**秒级备份**不能同时开启。<br />开启后，保留时长固定为7天。<br />开启后，最多支持保留10个备份（包括自动和手动）。已有10个备份时，手动创建备份会失败。 |

日志备份设置：

| 参数             | 说明                                                         |
| :--------------- | :----------------------------------------------------------- |
| **日志备份**     | 开启后可以实现按时间点恢复。默认为开启。                     |
| **日志备份保留** | 可选范围：7~730天。默认为7天，<br />必须小于等于数据备份天数。 |

#### 手动备份

1. 单击页面右上角的**备份实例**
2. 备份所有库或者特定库表。

| 实例类型   | 备份所有库                                                   | 备份特定库表                |
| :--------- | :----------------------------------------------------------- | :-------------------------- |
| 本地盘实例 | 两种方式：<br />**物理备份**（备份与恢复速度比逻辑备份快）<br />**逻辑备份** > **实例备份** | **逻辑备份** > **库表备份** |
| 云盘实例   | **快照备份**                                                 | 不支持                      |

### 库表级备份

RDS MySQL的自动备份始终备份所有库，您可以手动备份部分库。

在[RDS默认备份](https://help.aliyun.com/document_detail/98818.htm#section-iz5-u2s-xxr)设置中开启库表备份，开启后，新生成的备份将支持库表恢复。

手动备份部分库表：

1. 在页面右上角，单击**备份实例**。
2. 在对话框中，选择**备份方式**为**逻辑备份**，然后选择**备份策略**为**库表备份**。
3. 把需要手动备份的库添加到右侧，并单击**确定**

### 本地日志binlog

- MySQL实例默认生成Binlog规则

  - 通常情况下，写满500 MB就会生成新的Binlog日志文件继续写入。
  - 有些情况下，Binlog日志不满500 MB就不再写入，例如由于命令的执行、系统重启等原因。
  - 有些情况下，会出现Binlog文件尺寸超过500 MB的情况，例如当时在执行大事务，不断写入Binlog导致当前Binlog文件尺寸超过500 MB。

- MySQL实例默认清理Binlog规则

  超过以下任一规则限制时，Binlog会上传到OSS，然后从最早的Binlog开始清理，直到不超过规则限制。清理本地Binlog会有任务调度，有一定延迟。

  - 保存最近18个小时内的Binlog文件。
  - 保存最多60个Binlog文件。
  - 保证空间使用率（本地Binlog大小/实例总存储空间大小）不超过30%。
  - 保证实例存储空间使用率不超过80%或剩余空间不小于5 GB。

设置binlog上传规则：

1. 选择”备份恢复"
2. 选择“本地日志设置”

## 恢复

可使用命令行或图形界面进行逻辑数据还原。仅限通过 RDS 管理控制台 或 OPEN API 进行物理还原。

### 恢复全量数据

#### 恢复到新实例

恢复到一个新实例，验证数据后，再将数据迁回原实例

前提：

- 新实例的**白名单设置、备份设置、参数设置**和当前实例保持一致。
- 新实例内的数据信息与备份文件或时间点当时的信息一致。
- 新实例带有所使用备份文件或时间点当时的账号信息。

步骤：

1. 单击**备份恢复**

2. 单击**数据库恢复（原克隆实例）**

3. 设置：

   **还原方式**：**按时间点**：可以设置为日志备份保留时间内的任意时间点（任意一秒）

   ​                   **按备份集**：恢复所选备份集内的数据。备份集只能为物理备份

4. 登录到新实例并验证数据
5. （可选）将需要的数据从新实例迁移回原实例。

#### 恢复到原实例、其他实例

使用**DBS创建逻辑备份**，可以直接将其恢复至原实例或其它实例

### 恢复库表

前提：

- 实例是MySQL 8.0、5.7、5.6 高可用版（本地盘）或MySQL 5.7 三节点企业版（本地盘）。
- 实例的存储引擎不为X-Engine。
- 实例的表数量低于50000。
- 已在控制台***\*备份恢复\** > \**备份设置\****里开启库表备份功能。

影响：

如果恢复到原实例，恢复过程中**会进行主备切换**，RDS服务可能会出现约**30秒闪断**，请确保您的应用有自动重连机制

步骤：

1. 单击**备份恢复**，然后单击**库表恢复**。
2. 设置
3. 选择要恢复的库表，还可以设置恢复后的库名或表名，恢复到原实例时，**恢复后库名或表名不能与之前相同**，默认会在原库表名后添加_backup

### 恢复到自建mysql

#### 物理备份恢复

MySQL 5.7版本需要安装 Percona XtraBackup 2.4

MySQL 8.0版本需要安装 Percona XtraBackup 8.0

1. 安装数据恢复工具Percona XtraBackup 2.4
2. 安装解压工具qpress

```shell
wget "http://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/183466/cn_zh/1608011575185/qpress-11-linux-x64.tar"
tar xvf qpress-11-linux-x64.tar
chmod 775 qpress
cp qpress /usr/bin
```

3. 下载数据备份文件

4. 解压下载的数据备份文件

   对于tar 压缩包 （.tar.gz 后缀），使用命令：

   ```
   tar -izxvf <数据备份文件名> -C /home/mysql/data
   ```

   对于xbstream 压缩包 （.xb.gz 后缀），使用命令：

   ```
   gzip -d -c <数据备份文件名> | xbstream -x -v -C /home/mysql/data
   ```

   对于xbstream 文件包（_qp.xb 后缀），使用命令：

   ```
   ## 解包
   cat <数据备份文件名> | xbstream -x -v -C /home/mysql/data
   
   ## MySQL 5.6/5.7解压
   innobackupex --decompress --remove-original /home/mysql/data
   ## MySQL 8.0解压
   xtrabackup --decompress --remove-original --target-dir=/home/mysql/data
   ```

   对于xbstream qpress压缩包（_xb.qp后缀），使用命令：

   ```
   qpress -do  <数据备份文件名>  | xbstream -x -v -C /home/mysql/data
   ```

5. 查看解压后生成的文件,目录就是备份的数据库

   ```
   ls -l /home/mysql/data
   ```

6. 恢复解压的备份文件

   ```
   ## MySQL 5.6/5.7
   innobackupex --defaults-file=/home/mysql/data/backup-my.cnf --apply-log /home/mysql/data
   
   ## MySQL 8.0
   xtrabackup --prepare --target-dir=/home/mysql/data
   xtrabackup --datadir=/var/lib/mysql --copy-back --target-dir=/home/mysql/data
   ```

   若系统返回如下类似结果，则说明备份文件已成功恢复到自建数据库

   ![img](https://gitee.com/c_honghui/picture/raw/master/img/20210719101003.jpeg)

7. 为避免版本问题，需修改backup-my.cnf参数，具体操作步骤如下

   ```shell
   vi /home/mysql/data/backup-my.cnf
   #添加
   lower_case_table_names=1
   #注释
   #innodb_log_checksum_algorithm
   #innodb_fast_checksum
   #innodb_log_block_size
   #innodb_doublewrite_file
   #innodb_encrypt_algorithm
   #rds_encrypt_data
   #redo_log_version
   #master_key_id
   #server_uuid
   ```

8. 修改文件属主，并确定文件所属为MySQL用户

   ```bash
   chown -R mysql:mysql /home/mysql/data
   ```

9. 启动MySQL进程

   ```
   mysqld --defaults-file=/home/mysql/data/backup-my.cnf --user=mysql --datadir=/home/mysql/data &
   ```

#### 逻辑备份恢复

1. 下载并解压备份文件

2. 登录数据库创建对应的空数据库

   ```
   mysql -u root -p<数据库密码>
   create database <空数据库名>;
   exit
   ```

3. 将.sql文件导入对应数据库

   ```
   mysql -u root -p <空数据库名> < /tmp/解压缩的数据库文件
   ```

## 只读实例

创建只读实例时是从备实例复制数据，因此不会影响主实例

主实例的数据更新也会在主实例完成操作后立即自动同步到所有只读实例.

![image-20210419100049894](https://gitee.com/c_honghui/picture/raw/master/img/20210419100055.png)

特点:

- 建议只读实例规格**不小于主实例规格**，否则易导致只读实例延迟高、负载高等现象。
- 只读实例可以根据需要创建**最多10个**（小于64g内存是5个）；备实例数量是固定的1~2个
- 主实例被释放后，包年包月只读实例自动退款并释放
- 白名单：只读实例创建时会自动复制其主实例的白名单信息，但只读实例和主实例的白名单是相互独立的。

限制:

- 创建只读实例后，主实例将**不支持通过备份集**直接覆盖实例来恢复数据。
- 不支持创建和删除数据库、账号。

### 创建只读实例

1. 单击目标实例ID
2. 在**实例分布**区域的**只读实例**右侧单击**添加**。
3. 设置参数

### 只读实例延时复制

使只读实例延迟一段时间同步主实例数据

延时时间单位为秒，默认值为0，表示主实例完成操作后发送操作日志给只读实例，只读实例接收操作日志后立即执行。

设置了延时复制的只读实例，无法添加到读写分离中，需要修改为0才可以添加。

![img](https://gitee.com/c_honghui/picture/raw/master/img/20210419103103.png)

操作：

1. 找到只读实例单击实例ID
2. 在左侧导航栏中，选择**服务可用性**。
3. 单击**设置延时复制**。
4. 在弹出的对话框中，设置延时时间，单击**确定**。

### 创建异地灾备



## 迁移

使用DTS迁移数据，可以实现应用不停服务的情况下，平滑完成数据库的迁移工作。

注意:

数据迁移只会将本地数据库的数据（结构）复制一份到目标数据库，并不会对本地数据库数据（结构）造成影响

DTS在执行全量数据迁移时将占用源库和目标库一定的读写资源,可能会导致数据库的负载上升,建议**在业务低峰期**执行数据迁移（例如源库和目标库的CPU负载在30%以下）。

为保障数据一致性，在全量数据迁移期间请勿在源RDS实例中写入新的数据。

当需要将业务切换至目标实例，请务必先结束或释放迁移任务，避免该任务被自动恢复后，使用源端数据覆盖目标实例的数据。

DTS功能:

1.结构迁移(不收费)
DTS 会将本地数据库的结构定义迁移到目标实例。目前 DTS 支持结构迁移的对象有：表、视图、触发器、存储过程、存储函数
2.全量迁移(不收费)
DTS 会将本地数据库迁移对象的数据全部迁移到目标实例。如果用户还选择了增量迁移，那么全量迁移过程中，为了保证数据一致性，**无主键的非事务表会被锁定**，锁定期间这些表无法写入，锁定时长依赖于这些表的数据量大小，在这些无主键非事务表迁移完成后，锁才会释放。
3.增量迁移(收费)
增量迁移会将迁移过程进行数据变更同步到目标实例，如果迁移期间进行了DDL 操作，那么这些结构**变更不会迁移**到目标实例。

迁移限制:

```text
1.迁移过程中不支持DDL操作
2.结构迁移不支持EVENT迁移
3.如果使用了对象名映射功能后，依赖这个对象的其他对象可能迁移失败
4.当增量迁移时，本地MySQL实例需要开启binlog，且本地库的binlog_format要为ROW，如果是5.6版本，binlog_row_image还要设置为full
```

迁移步骤:

1. 单击**数据迁移**

2. 选择迁移的目标实例所属地域

3. 配置源库和目标库

4. 选择迁移对象和类型

   - 如果只需要进行全量迁移，请同时勾选**结构迁移**和**全量数据迁移**。
   - 如果需要进行不停机迁移，请同时勾选**结构迁移**、**全量数据迁移**和**增量数据迁移**
   - 如果未选择**增量数据迁移**，为保障数据一致性，数据迁移期间请勿在源RDS实例中写入新的数据。

5. 单击**购买并启动**，迁移任务正式开始

   - 全量数据迁移

     **请勿手动结束**迁移任务，否则可能导致数据不完整。您只需等待迁移任务完成即可，迁移任务会自动结束。

   - 增量数据迁移

     迁移任务**不会自动结束**，您需要手动结束迁移任务。

     1. 观察迁移任务的进度变更为**增量迁移**，并显示为**无延迟**状态时，将源库停写几分钟，此时**增量迁移**的状态可能会显示延迟的时间。
     2. 等待迁移任务的**增量迁移**再次进入**无延迟**状态后，手动结束迁移任务。

## 性能优化与诊断

### 慢sql问题

#### sql异常

架构设计和库表索引设计不合理、索引缺失、扫描行数太多等会导致sql异常。
可以在控制台的**SQL洞察**页面，查看慢SQL的执行耗时、执行次数等信息。

#### 实例瓶颈

原因：

- 业务量持续增长而没有扩容。
- 硬件老化，性能有损耗。
- 数据量一直增加，数据结构也有变化，导致原来不慢的SQL变成慢SQL。

可以在控制台的**监控与报警**页面，单击**标准监控**页签，在**资源监控**内可以查看实例的资源使用情况。如果资源使用率各项指标都接近100%，可能是实例到达了瓶颈。

解决：

先测试出实例的性能基准值，例如用SysBench进行[基准测试](https://help.aliyun.com/document_detail/151977.htm#task-2399303)，复杂场景下的QPS和TPS很少会超过基准值。

确认实例到达瓶颈后，建议升级实例规格。

#### 参数设置不当

参数**innodb_buffer_pool_instances**、**join_buffer_size**等设置不当会导致性能变慢。

您可以在控制台的**参数设置**页面，单击**修改历史**页签，查看实例的参数修改情况。

#### 缓存失效

如果缓存失效，也会有大量的查询路由到数据库端，导致性能下降。

可以在控制台的**监控与报警**页面，单击**标准监控**页签，在**引擎监控**内可以查看实例的缓存命中率、QPS、TPS等。

#### 批量操作

如果有大批量的数据导入、删除、查询操作，会导致SQL执行变慢。

可以从磁盘空间、SQL洞察或者慢查询里找到对应语句。例如查看Binlog大小，正常情况单个Binlog大小是**500 MB**，如果有超过500 MB的，可以查看是否有异常。

#### 未关闭事务

如果某个任务突然变慢，查看CPU和IOPS的使用率并不高，而且活跃会话持续增多，通常是因为存在未关闭的事务。

检查导致事务冲突的锁并中止对应的SQL语句。

#### 定时任务

如果实例负载随时间有规律性变化，可能是存在定时任务。

#### 总结

RDS上定位慢SQL的主要方法如下：

- 检查监控指标
- 查看慢日志明细
- 使用SQL洞察
- 使用自治服务

### 内存问题

#### 查看内存使用情况

- 监控与报警

- 数据库自治服务DAS

  在控制台的***\*自治服务\** > \**性能趋势\****页面，单击**性能趋势**页签，查看**MySQL CPU/内存 利用率**和**InnoDB Buffer Pool 命中率**情况。

- 使用performance_schema

  - 要在实例启动时开启内存检测，请修改my.cnf文件，添加`performance_schema = on`，然后重启实例即生效。

  - 要在实例运行中开启内存检测，请执行如下命令：

    ```mysql
    update performance_schema.setup_instruments set enabled = 'yes' where name like 'memory%';
    ```

从各个维度统计内存消耗的相关表如下：

- memory_summary_by_account_by_event_name：统计指定帐户（用户和主机组合）的事件和事件名称。
- memory_summary_by_host_by_event_name：统计指定主机的事件和事件名称。
- memory_summary_by_thread_by_event_name：统计指定线程的事件和事件名称。
- memory_summary_by_user_by_event_name：统计指定用户的事件和事件名称。
- memory_summary_global_by_event_name：统计指定事件名称的事件。

#### 内存高原因

通常InnoDB Buffer Pool的内存占用是最大的，Buffer Pool的内存占用上限受到Buffer Pool配置参数的限制，但是还有很多内存是在请求执行中动态分配和调整的，例如内存临时表消耗的内存、prefetch cache、table cache、哈希索引、行锁对象等

#### 多语句

MySQL支持将多个SQL语句用英文分号（;）分隔，然后一起发给MySQL，MySQL会逐条处理SQL，但是某些内存需要等到所有的SQL执行结束才释放。

一般场景下，如果存在大批量的multiple statements，网络流量会有突增，可以从网络流量监控和SQL洞察，判断是否有这种现象。建议业务实现中尽量避免multiple statements的SQL发送方式。

#### 缓冲池问题

所有表的数据页都存放在缓冲池中，查询执行的时候如果需要的数据页直接命中缓冲池，就不会发生物理I/O，SQL执行的效率较高，缓冲池采用LRU算法管理数据页，所有的脏页放到Flush List链表中。

RDS MySQL的InnoDB Buffer Pool大小默认设置为内存的75%，这部分内存通常是实例内存中占比最大的。

Buffer Pool相关的常见问题：

- 数据页预热不足导致查询的延迟较高。通常发生在实例重启、冷数据读取或缓冲池命中率较低的场景，建议升级实例规格或大促前预热数据。
- 脏页累积太多。当未刷新脏页的最旧LSN和当前LSN的距离超过76%时，会触发用户线程同步刷新脏页，导致实例性能严重下降。优化方式是均衡写入负载、避免写入吞吐过高、调整刷新脏页参数或升级实例规格等。
- 高内存实例的参数**innodb_buffer_pool_instances**设置较小。高QPS负载情况下，缓冲池的锁竞争会比较激烈。建议高内存的实例将参数**innodb_buffer_pool_instances**设置为8或16，甚至更高。

#### 临时表

内存临时表大小受到参数**tmp_table_size**和**max_heap_table_size**限制，超过限制后将转化为磁盘临时表，如果瞬间有大量的连接创建大量的临时表，可能会造成内存突增。MySQL 8.0实现了新的temptable engine，所有线程分配的内存临时表大小之和必须小于参数**temptable_max_ram**，**temptable_max_ram**默认为1 GB，超出后转换为磁盘临时表。

###　空间不足

如果实例的存储空间不足，会导致严重后果，例如数据库无法写入、数据库无法备份、存储空间扩容任务耗时过长等。

登录数据库后执行命令`show table status like '<表名>';`查看表空间。

#### 索引太多导致空间不足

- 现象

  通常表上除了主键索引，还存在二级索引，二级索引越多，整个表空间越大。

- 解决方案

  优化数据结构，减少二级索引数量。

#### 大字段导致空间不足

- 现象

  如果表结构定义中有blob、text等大字段或很长的varchar字段，也会占用更大的表空间。

- 解决方案

  将数据压缩以后再插入。

#### 空闲表空间太多导致空间不足

- 现象

  空闲表空间太多是指InnoDB表的碎片率高。InnoDB是按页（Page）管理表空间的，如果Page写满记录，然后部分记录又被删除，后续这些删除的记录位置又没有新的记录插入，就会产生很多空闲空间。

- 解决方案

  可以通过命令`show table status like '<表名>';`查看表上空闲的空间，如果空闲空间过大，可以执行命令`optimize table <表名>;`整理表空间。

#### 临时表空间过大导致空间不足

- 现象
  - 半连接（Semi-join）、去重（distinct）、不走索引的排序等操作，会创建临时表，如果涉及的数据量过多，可能导致临时表空间特别大。
  - DDL操作重建表空间时，如果表特别大，创建索引排序时产生的临时文件也会特别大。RDS MySQL 5.6和5.7不支持即时增加字段，很多DDL是通过创建新表实现的，DDL执行结束再删除旧表，DDL过程中会同时存在两份表。
- 解决方案
  - 可以查看执行计划，确认是否包含**Using Temporary**。
  - 大表DDL需要注意实例的空间是否足够，不足的话需要提前[升级存储空间](https://help.aliyun.com/document_detail/96061.htm#concept-efl-pln-wdb)。

#### 空间优化方案

- 使用[空间碎片自动回收](https://help.aliyun.com/document_detail/198468.htm#task-2024282)。开启该功能后，主实例会自动执行Optimize Table命令来回收表空间碎片，帮助您整理物理空间碎片。
- 使用[云盘存储](https://help.aliyun.com/document_detail/69795.htm#concept-kpg-5wx-5db)。云盘支持的存储空间比本地盘更大。
- 采用[分析型数据库](https://help.aliyun.com/document_detail/93776.htm)。

### I/O高问题

I/O性能受硬件层存储介质、软件层内核架构和具体sql语句影响

#### 存储类型

- 本地SSD盘

  本地SSD盘拥有最低的I/O延迟，但是本地SSD盘的存储大小有限，如果数据增多，本地空间不够时，需要迁移数据到其他的主机，时间较长且切换时会有闪断。

- 云盘（分布式存储）

  云盘包括SSD云盘和ESSD云盘，云盘拥有更高的性价比，支持更大的存储空间，扩容速度快且不需要迁移数据。

#### 高吞吐导致IO高

如果表上有很多索引或大字段，频繁更新、删除、插入，读取数据和刷新脏页时会有大量的IO

优化刷新脏页相关的参数来解决高吞吐问题：

- **innodb_max_dirty_pages_pct**：缓冲池中允许的脏页百分比，默认值为75。
- **innodb_max_dirty_pages_pct_lwm**：脏页比例的低水位线。当缓冲池里的脏页比例超过这个低水位线时，能够触发脏页预刷功能，逐步控制脏页比例。默认值为0，表示禁用该功能。
- **innodb_io_capacity**：设置InnoDB后台任务每秒执行的I/O操作数的上限，影响刷新脏页和写入缓冲池的速率。默认值为20000。
- **innodb_io_capacity_max**：如果刷新操作过于落后，InnoDB可以超过**innodb_io_capacity**的限制进行刷新，但是不能超过本参数的值。默认值为40000。

#### 临时表导致实例IO高

如果临时目录很大，可能存在慢SQL排序、去重等操作导致创建很大的临时表。临时表写入也会造成I/O增加。

建议进行SQL优化，避免慢SQL

#### 读取冷数据导致实例I/O高

如果SQL查询或修改的数据不在缓冲池（Buffer Pool），则需要从存储中读取，可能会产生大量的I/O吞吐。

根据业务场景重新设计缓存策略，或者升级实例规格。

#### DDL语句导致实例I/O高

DDL语句可能会重建表空间，期间会扫描全表数据、创建索引排序、刷新新表产生的脏页，这些都会导致大量的I/O吞吐。另外一种场景是删除大表造成的I/O抖动。

#### 大事务写Binlog导致实例I/O高

事务只有在提交时才会写Binlog文件，如果存在大事务，例如一条Delete语句删除大量的行，可能会产生几十GB的Binlog文件，Binlog文件刷新到磁盘时，会造成很高的I/O吞吐。

### 活跃线程数高问题

活跃线程数或活跃连接数是衡量MySQL负载状态的关键指标，通常来说一个比较健康的实例活跃连接数应该低于10，高规格和高QPS的实例活跃连接数可能20、30，如果出现几百、上千的活跃连接数，说明出现了SQL堆积和响应变慢，严重时会导致实例停止响应，无法继续处理SQL请求。

#### 排查慢SQL堆积问题

如果通过监控发现活跃线程数升高，首先通过`show processlist;`命令查看是否有慢SQL。如果有很多扫描行数太多的SQL，容易导致活跃连接数升高。

#### 排查表缓存（Table Cache）问题

- 现象

  Table Cache不足时，会导致大量SQL处于`Opening table`状态，在QPS过高或者表很多的场景容易出现。

- 解决方案

  将参数**table_open_cache**（不需要重启实例）和**table_open_cache_instances**（需要重启实例）调大。

#### 排查元数据锁（MDL）问题

- 现象

  出现MDL锁时，会导致大量SQL处于`Waiting for table metadata lock`的状态，在DDL prepare和commit阶段，DDL语句需要获取MDL锁，如果表上有未提交事务或慢SQL，会阻塞DDL操作，DDL操作又会阻塞其他的SQL，最终导致活跃线程数升高。

- 解决方案

  中止未提交事务、慢SQL或正在执行的DDL都可以解决问题。

#### 排查行锁冲突问题

- 现象

  行锁冲突表现为**Innodb_row_lock_waits**和**Innodb_row_lock_time**监控项的指标升高。

可以通过`show engine innodb status;`命令查看是否有大量会话处于`Lock wait`状态，如果有，说明行锁冲突比较严重，需要通过优化热点更新、降低事务大小、及时提交事务等方法避免行锁冲突。

### 自治服务DAS

