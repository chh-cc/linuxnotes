- 

## 备份



### 自动备份与手动备份

- 只读实例不支持备份设置。
- 备份期间不要执行DDL操作，避免锁表导致备份失败。
- 尽量选择业务低峰期进行备份。
- 表数量超过60万将无法进行备份。表数量过多时建议进行分库。
- 备份的表数量超过5万张将无法进行单库单表恢复。

#### 自动备份

数据备份无法关闭，您可以修改数据备份的频率。日志备份可以关闭

备份设置：

2. 单击**备份恢复**
3. 选择**备份设置**页签，单击**编辑**

数据备份设置：

| 实例类型       | 参数             | 说明                                                         |
| :------------- | :--------------- | :----------------------------------------------------------- |
| **所有实例**   | **备份周期**     | 每周至少选2天进行数据备份。                                  |
|                | **保留时长**     | 默认为7天。可选范围：<br />云盘版：7~730天。<br />**说明**<br />保留不超过730天的数据备份为常规备份。<br />保留超过730天的数据备份为归档备份，费用较低。<br />**说明** 如果设置超过730天，或者勾选**实例释放前长期保留**，则还需设置归档备份的保留个数，例如保留每个月最早的2个归档备份。 |
| **本地盘实例** | **库表备份**     | 开启后将支持[MySQL单库单表恢复](https://help.aliyun.com/document_detail/103175.htm#concept-ocr-swk-ngb)。默认为开启，无法关闭。<br />**说明**<br />仅RDS MySQL 8.0、5.7、5.6 高可用版（本地盘）支持。<br />开启后，新生成的备份文件将逐步采用新的备份格式。 |
| **云盘实例**   | **增加快照频率** | 勾选后，可设置每N小时备份1次，甚至每15分钟备份一次。<br />**说明**<br />仅高可用云盘版支持。<br />**增加快照频率**和**秒级备份**不能同时开启。<br />开启后，最大保留时长会减少。 |
|                | **秒级备份**     | 开启后，每次备份只需1秒即可完成。<br />**说明**<br />仅高可用ESSD云盘版支持。<br />**增加快照频率**和**秒级备份**不能同时开启。<br />开启后，保留时长固定为7天。<br />开启后，最多支持保留10个备份（包括自动和手动）。已有10个备份时，手动创建备份会失败。 |

日志备份设置：

| 参数             | 说明                                                         |
| :--------------- | :----------------------------------------------------------- |
| **日志备份**     | 开启后可以实现按时间点恢复。默认为开启。                     |
| **日志备份保留** | 可选范围：7~730天。默认为7天，<br />必须小于等于数据备份天数。 |

#### 手动备份

1. 单击页面右上角的**备份实例**
2. 备份所有库或者特定库表。

| 实例类型   | 备份所有库                                                   | 备份特定库表                |
| :--------- | :----------------------------------------------------------- | :-------------------------- |
| 本地盘实例 | 两种方式：<br />**物理备份**（备份与恢复速度比逻辑备份快）<br />**逻辑备份** > **实例备份** | **逻辑备份** > **库表备份** |
| 云盘实例   | **快照备份**                                                 | 不支持                      |

### 库表级备份

RDS MySQL的自动备份始终备份所有库，您可以手动备份部分库。

在[RDS默认备份](https://help.aliyun.com/document_detail/98818.htm#section-iz5-u2s-xxr)设置中开启库表备份，开启后，新生成的备份将支持库表恢复。

手动备份部分库表：

1. 在页面右上角，单击**备份实例**。
2. 在对话框中，选择**备份方式**为**逻辑备份**，然后选择**备份策略**为**库表备份**。
3. 把需要手动备份的库添加到右侧，并单击**确定**

### 本地日志binlog

- MySQL实例默认生成Binlog规则

  - 通常情况下，写满500 MB就会生成新的Binlog日志文件继续写入。
  - 有些情况下，Binlog日志不满500 MB就不再写入，例如由于命令的执行、系统重启等原因。
  - 有些情况下，会出现Binlog文件尺寸超过500 MB的情况，例如当时在执行大事务，不断写入Binlog导致当前Binlog文件尺寸超过500 MB。

- MySQL实例默认清理Binlog规则

  超过以下任一规则限制时，Binlog会上传到OSS，然后从最早的Binlog开始清理，直到不超过规则限制。清理本地Binlog会有任务调度，有一定延迟。

  - 保存最近18个小时内的Binlog文件。
  - 保存最多60个Binlog文件。
  - 保证空间使用率（本地Binlog大小/实例总存储空间大小）不超过30%。
  - 保证实例存储空间使用率不超过80%或剩余空间不小于5 GB。

设置binlog上传规则：

1. 选择”备份恢复"
2. 选择“本地日志设置”

## 恢复

可使用命令行或图形界面进行逻辑数据还原。仅限通过 RDS 管理控制台 或 OPEN API 进行物理还原。

### 恢复全量数据

#### 恢复到新实例

恢复到一个新实例，验证数据后，再将数据迁回原实例

前提：

- 新实例的**白名单设置、备份设置、参数设置**和当前实例保持一致。
- 新实例内的数据信息与备份文件或时间点当时的信息一致。
- 新实例带有所使用备份文件或时间点当时的账号信息。

步骤：

1. 单击**备份恢复**

2. 单击**数据库恢复（原克隆实例）**

3. 设置：

   **还原方式**：**按时间点**：可以设置为日志备份保留时间内的任意时间点（任意一秒）

   ​                   **按备份集**：恢复所选备份集内的数据。备份集只能为物理备份

4. 登录到新实例并验证数据
5. （可选）将需要的数据从新实例迁移回原实例。

#### 恢复到原实例、其他实例

使用**DBS创建逻辑备份**，可以直接将其恢复至原实例或其它实例

### 恢复库表

前提：

- 实例是MySQL 8.0、5.7、5.6 高可用版（本地盘）或MySQL 5.7 三节点企业版（本地盘）。
- 实例的存储引擎不为X-Engine。
- 实例的表数量低于50000。
- 已在控制台***\*备份恢复\** > \**备份设置\****里开启库表备份功能。

影响：

如果恢复到原实例，恢复过程中**会进行主备切换**，RDS服务可能会出现约**30秒闪断**，请确保您的应用有自动重连机制

步骤：

1. 单击**备份恢复**，然后单击**库表恢复**。
2. 设置
3. 选择要恢复的库表，还可以设置恢复后的库名或表名，恢复到原实例时，**恢复后库名或表名不能与之前相同**，默认会在原库表名后添加_backup

### 恢复到自建mysql

#### 物理备份恢复

MySQL 5.7版本需要安装 Percona XtraBackup 2.4

MySQL 8.0版本需要安装 Percona XtraBackup 8.0

1. 安装数据恢复工具Percona XtraBackup 2.4
2. 安装解压工具qpress

```shell
wget "http://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/183466/cn_zh/1608011575185/qpress-11-linux-x64.tar"
tar xvf qpress-11-linux-x64.tar
chmod 775 qpress
cp qpress /usr/bin
```

3. 下载数据备份文件

4. 解压下载的数据备份文件

   对于tar 压缩包 （.tar.gz 后缀），使用命令：

   ```
   tar -izxvf <数据备份文件名> -C /home/mysql/data
   ```

   对于xbstream 压缩包 （.xb.gz 后缀），使用命令：

   ```
   gzip -d -c <数据备份文件名> | xbstream -x -v -C /home/mysql/data
   ```

   对于xbstream 文件包（_qp.xb 后缀），使用命令：

   ```
   ## 解包
   cat <数据备份文件名> | xbstream -x -v -C /home/mysql/data
   
   ## MySQL 5.6/5.7解压
   innobackupex --decompress --remove-original /home/mysql/data
   ## MySQL 8.0解压
   xtrabackup --decompress --remove-original --target-dir=/home/mysql/data
   ```

   对于xbstream qpress压缩包（_xb.qp后缀），使用命令：

   ```
   qpress -do  <数据备份文件名>  | xbstream -x -v -C /home/mysql/data
   ```

5. 查看解压后生成的文件,目录就是备份的数据库

   ```
   ls -l /home/mysql/data
   ```

6. 恢复解压的备份文件

   ```
   ## MySQL 5.6/5.7
   innobackupex --defaults-file=/home/mysql/data/backup-my.cnf --apply-log /home/mysql/data
   
   ## MySQL 8.0
   xtrabackup --prepare --target-dir=/home/mysql/data
   xtrabackup --datadir=/var/lib/mysql --copy-back --target-dir=/home/mysql/data
   ```

   若系统返回如下类似结果，则说明备份文件已成功恢复到自建数据库

   ![img](https://gitee.com/c_honghui/picture/raw/master/img/20210719101003.jpeg)

7. 为避免版本问题，需修改backup-my.cnf参数，具体操作步骤如下

   ```shell
   vi /home/mysql/data/backup-my.cnf
   #添加
   lower_case_table_names=1
   #注释
   #innodb_log_checksum_algorithm
   #innodb_fast_checksum
   #innodb_log_block_size
   #innodb_doublewrite_file
   #innodb_encrypt_algorithm
   #rds_encrypt_data
   #redo_log_version
   #master_key_id
   #server_uuid
   ```

8. 修改文件属主，并确定文件所属为MySQL用户

   ```bash
   chown -R mysql:mysql /home/mysql/data
   ```

9. 启动MySQL进程

   ```
   mysqld --defaults-file=/home/mysql/data/backup-my.cnf --user=mysql --datadir=/home/mysql/data &
   ```

#### 逻辑备份恢复

1. 下载并解压备份文件

2. 登录数据库创建对应的空数据库

   ```
   mysql -u root -p<数据库密码>
   create database <空数据库名>;
   exit
   ```

3. 将.sql文件导入对应数据库

   ```
   mysql -u root -p <空数据库名> < /tmp/解压缩的数据库文件
   ```

## 只读实例

创建只读实例时是从备实例复制数据，因此不会影响主实例

主实例的数据更新也会在主实例完成操作后立即自动同步到所有只读实例.

![image-20210419100049894](https://gitee.com/c_honghui/picture/raw/master/img/20210419100055.png)

特点:

- 建议只读实例规格**不小于主实例规格**，否则易导致只读实例延迟高、负载高等现象。
- 只读实例可以根据需要创建**最多10个**（小于64g内存是5个）；备实例数量是固定的1~2个
- 主实例被释放后，包年包月只读实例自动退款并释放
- 白名单：只读实例创建时会自动复制其主实例的白名单信息，但只读实例和主实例的白名单是相互独立的。

限制:

- 创建只读实例后，主实例将**不支持通过备份集**直接覆盖实例来恢复数据。
- 不支持创建和删除数据库、账号。

### 创建只读实例

1. 单击目标实例ID
2. 在**实例分布**区域的**只读实例**右侧单击**添加**。
3. 设置参数

### 只读实例延时复制

使只读实例延迟一段时间同步主实例数据

延时时间单位为秒，默认值为0，表示主实例完成操作后发送操作日志给只读实例，只读实例接收操作日志后立即执行。

设置了延时复制的只读实例，无法添加到读写分离中，需要修改为0才可以添加。

![img](https://gitee.com/c_honghui/picture/raw/master/img/20210419103103.png)

操作：

1. 找到只读实例单击实例ID
2. 在左侧导航栏中，选择**服务可用性**。
3. 单击**设置延时复制**。
4. 在弹出的对话框中，设置延时时间，单击**确定**。

### 创建异地灾备



## 迁移

使用DTS迁移数据，可以实现应用不停服务的情况下，平滑完成数据库的迁移工作。

注意:

数据迁移只会将本地数据库的数据（结构）复制一份到目标数据库，并不会对本地数据库数据（结构）造成影响

DTS在执行全量数据迁移时将占用源库和目标库一定的读写资源,可能会导致数据库的负载上升,建议**在业务低峰期**执行数据迁移（例如源库和目标库的CPU负载在30%以下）。

为保障数据一致性，在全量数据迁移期间请勿在源RDS实例中写入新的数据。

当需要将业务切换至目标实例，请务必先结束或释放迁移任务，避免该任务被自动恢复后，使用源端数据覆盖目标实例的数据。

DTS功能:

1.结构迁移(不收费)
DTS 会将本地数据库的结构定义迁移到目标实例。目前 DTS 支持结构迁移的对象有：表、视图、触发器、存储过程、存储函数
2.全量迁移(不收费)
DTS 会将本地数据库迁移对象的数据全部迁移到目标实例。如果用户还选择了增量迁移，那么全量迁移过程中，为了保证数据一致性，**无主键的非事务表会被锁定**，锁定期间这些表无法写入，锁定时长依赖于这些表的数据量大小，在这些无主键非事务表迁移完成后，锁才会释放。
3.增量迁移(收费)
增量迁移会将迁移过程进行数据变更同步到目标实例，如果迁移期间进行了DDL 操作，那么这些结构**变更不会迁移**到目标实例。

迁移限制:

```text
1.迁移过程中不支持DDL操作
2.结构迁移不支持EVENT迁移
3.如果使用了对象名映射功能后，依赖这个对象的其他对象可能迁移失败
4.当增量迁移时，本地MySQL实例需要开启binlog，且本地库的binlog_format要为ROW，如果是5.6版本，binlog_row_image还要设置为full
```

迁移步骤:

1. 单击**数据迁移**

2. 选择迁移的目标实例所属地域

3. 配置源库和目标库

4. 选择迁移对象和类型

   - 如果只需要进行全量迁移，请同时勾选**结构迁移**和**全量数据迁移**。
   - 如果需要进行不停机迁移，请同时勾选**结构迁移**、**全量数据迁移**和**增量数据迁移**
   - 如果未选择**增量数据迁移**，为保障数据一致性，数据迁移期间请勿在源RDS实例中写入新的数据。

5. 单击**购买并启动**，迁移任务正式开始

   - 全量数据迁移

     **请勿手动结束**迁移任务，否则可能导致数据不完整。您只需等待迁移任务完成即可，迁移任务会自动结束。

   - 增量数据迁移

     迁移任务**不会自动结束**，您需要手动结束迁移任务。

     1. 观察迁移任务的进度变更为**增量迁移**，并显示为**无延迟**状态时，将源库停写几分钟，此时**增量迁移**的状态可能会显示延迟的时间。
     2. 等待迁移任务的**增量迁移**再次进入**无延迟**状态后，手动结束迁移任务。

## 性能优化与诊断

### 慢sql问题

#### sql异常

架构设计和库表索引设计不合理、索引缺失、扫描行数太多等会导致sql异常。
可以在控制台的**SQL洞察**页面，查看慢SQL的执行耗时、执行次数等信息。

#### 实例瓶颈

原因：

- 业务量持续增长而没有扩容。
- 硬件老化，性能有损耗。
- 数据量一直增加，数据结构也有变化，导致原来不慢的SQL变成慢SQL。

可以在控制台的**监控与报警**页面，单击**标准监控**页签，在**资源监控**内可以查看实例的资源使用情况。如果资源使用率各项指标都接近100%，可能是实例到达了瓶颈。

解决：

先测试出实例的性能基准值，例如用SysBench进行[基准测试](https://help.aliyun.com/document_detail/151977.htm#task-2399303)，复杂场景下的QPS和TPS很少会超过基准值。

确认实例到达瓶颈后，建议升级实例规格。

#### 参数设置不当

参数**innodb_buffer_pool_instances**、**join_buffer_size**等设置不当会导致性能变慢。

您可以在控制台的**参数设置**页面，单击**修改历史**页签，查看实例的参数修改情况。

#### 缓存失效

如果缓存失效，也会有大量的查询路由到数据库端，导致性能下降。

可以在控制台的**监控与报警**页面，单击**标准监控**页签，在**引擎监控**内可以查看实例的缓存命中率、QPS、TPS等。

#### 批量操作

如果有大批量的数据导入、删除、查询操作，会导致SQL执行变慢。

可以从磁盘空间、SQL洞察或者慢查询里找到对应语句。例如查看Binlog大小，正常情况单个Binlog大小是**500 MB**，如果有超过500 MB的，可以查看是否有异常。

#### 未关闭事务

如果某个任务突然变慢，查看CPU和IOPS的使用率并不高，而且活跃会话持续增多，通常是因为存在未关闭的事务。

检查导致事务冲突的锁并中止对应的SQL语句。

#### 定时任务

如果实例负载随时间有规律性变化，可能是存在定时任务。

#### 总结

RDS上定位慢SQL的主要方法如下：

- 检查监控指标
- 查看慢日志明细
- 使用SQL洞察
- 使用自治服务

### 内存问题

#### 查看内存使用情况

- 监控与报警

- 数据库自治服务DAS

  在控制台的***\*自治服务\** > \**性能趋势\****页面，单击**性能趋势**页签，查看**MySQL CPU/内存 利用率**和**InnoDB Buffer Pool 命中率**情况。

- 使用performance_schema

  - 要在实例启动时开启内存检测，请修改my.cnf文件，添加`performance_schema = on`，然后重启实例即生效。

  - 要在实例运行中开启内存检测，请执行如下命令：

    ```mysql
    update performance_schema.setup_instruments set enabled = 'yes' where name like 'memory%';
    ```

从各个维度统计内存消耗的相关表如下：

- memory_summary_by_account_by_event_name：统计指定帐户（用户和主机组合）的事件和事件名称。
- memory_summary_by_host_by_event_name：统计指定主机的事件和事件名称。
- memory_summary_by_thread_by_event_name：统计指定线程的事件和事件名称。
- memory_summary_by_user_by_event_name：统计指定用户的事件和事件名称。
- memory_summary_global_by_event_name：统计指定事件名称的事件。

#### 内存高原因

通常InnoDB Buffer Pool的内存占用是最大的，Buffer Pool的内存占用上限受到Buffer Pool配置参数的限制，但是还有很多内存是在请求执行中动态分配和调整的，例如内存临时表消耗的内存、prefetch cache、table cache、哈希索引、行锁对象等

#### 多语句

MySQL支持将多个SQL语句用英文分号（;）分隔，然后一起发给MySQL，MySQL会逐条处理SQL，但是某些内存需要等到所有的SQL执行结束才释放。

一般场景下，如果存在大批量的multiple statements，网络流量会有突增，可以从网络流量监控和SQL洞察，判断是否有这种现象。建议业务实现中尽量避免multiple statements的SQL发送方式。

#### 缓冲池问题

所有表的数据页都存放在缓冲池中，查询执行的时候如果需要的数据页直接命中缓冲池，就不会发生物理I/O，SQL执行的效率较高，缓冲池采用LRU算法管理数据页，所有的脏页放到Flush List链表中。

RDS MySQL的InnoDB Buffer Pool大小默认设置为内存的75%，这部分内存通常是实例内存中占比最大的。

Buffer Pool相关的常见问题：

- 数据页预热不足导致查询的延迟较高。通常发生在实例重启、冷数据读取或缓冲池命中率较低的场景，建议升级实例规格或大促前预热数据。
- 脏页累积太多。当未刷新脏页的最旧LSN和当前LSN的距离超过76%时，会触发用户线程同步刷新脏页，导致实例性能严重下降。优化方式是均衡写入负载、避免写入吞吐过高、调整刷新脏页参数或升级实例规格等。
- 高内存实例的参数**innodb_buffer_pool_instances**设置较小。高QPS负载情况下，缓冲池的锁竞争会比较激烈。建议高内存的实例将参数**innodb_buffer_pool_instances**设置为8或16，甚至更高。

#### 临时表

内存临时表大小受到参数**tmp_table_size**和**max_heap_table_size**限制，超过限制后将转化为磁盘临时表，如果瞬间有大量的连接创建大量的临时表，可能会造成内存突增。MySQL 8.0实现了新的temptable engine，所有线程分配的内存临时表大小之和必须小于参数**temptable_max_ram**，**temptable_max_ram**默认为1 GB，超出后转换为磁盘临时表。

###　空间不足

如果实例的存储空间不足，会导致严重后果，例如数据库无法写入、数据库无法备份、存储空间扩容任务耗时过长等。

登录数据库后执行命令`show table status like '<表名>';`查看表空间。

#### 索引太多导致空间不足

- 现象

  通常表上除了主键索引，还存在二级索引，二级索引越多，整个表空间越大。

- 解决方案

  优化数据结构，减少二级索引数量。

#### 大字段导致空间不足

- 现象

  如果表结构定义中有blob、text等大字段或很长的varchar字段，也会占用更大的表空间。

- 解决方案

  将数据压缩以后再插入。

#### 空闲表空间太多导致空间不足

- 现象

  空闲表空间太多是指InnoDB表的碎片率高。InnoDB是按页（Page）管理表空间的，如果Page写满记录，然后部分记录又被删除，后续这些删除的记录位置又没有新的记录插入，就会产生很多空闲空间。

- 解决方案

  可以通过命令`show table status like '<表名>';`查看表上空闲的空间，如果空闲空间过大，可以执行命令`optimize table <表名>;`整理表空间。

#### 临时表空间过大导致空间不足

- 现象
  - 半连接（Semi-join）、去重（distinct）、不走索引的排序等操作，会创建临时表，如果涉及的数据量过多，可能导致临时表空间特别大。
  - DDL操作重建表空间时，如果表特别大，创建索引排序时产生的临时文件也会特别大。RDS MySQL 5.6和5.7不支持即时增加字段，很多DDL是通过创建新表实现的，DDL执行结束再删除旧表，DDL过程中会同时存在两份表。
- 解决方案
  - 可以查看执行计划，确认是否包含**Using Temporary**。
  - 大表DDL需要注意实例的空间是否足够，不足的话需要提前[升级存储空间](https://help.aliyun.com/document_detail/96061.htm#concept-efl-pln-wdb)。

#### 空间优化方案

- 使用[空间碎片自动回收](https://help.aliyun.com/document_detail/198468.htm#task-2024282)。开启该功能后，主实例会自动执行Optimize Table命令来回收表空间碎片，帮助您整理物理空间碎片。
- 使用[云盘存储](https://help.aliyun.com/document_detail/69795.htm#concept-kpg-5wx-5db)。云盘支持的存储空间比本地盘更大。
- 采用[分析型数据库](https://help.aliyun.com/document_detail/93776.htm)。

### I/O高问题

I/O性能受硬件层存储介质、软件层内核架构和具体sql语句影响

#### 存储类型

- 本地SSD盘

  本地SSD盘拥有最低的I/O延迟，但是本地SSD盘的存储大小有限，如果数据增多，本地空间不够时，需要迁移数据到其他的主机，时间较长且切换时会有闪断。

- 云盘（分布式存储）

  云盘包括SSD云盘和ESSD云盘，云盘拥有更高的性价比，支持更大的存储空间，扩容速度快且不需要迁移数据。

#### 高吞吐导致IO高

如果表上有很多索引或大字段，频繁更新、删除、插入，读取数据和刷新脏页时会有大量的IO

优化刷新脏页相关的参数来解决高吞吐问题：

- **innodb_max_dirty_pages_pct**：缓冲池中允许的脏页百分比，默认值为75。
- **innodb_max_dirty_pages_pct_lwm**：脏页比例的低水位线。当缓冲池里的脏页比例超过这个低水位线时，能够触发脏页预刷功能，逐步控制脏页比例。默认值为0，表示禁用该功能。
- **innodb_io_capacity**：设置InnoDB后台任务每秒执行的I/O操作数的上限，影响刷新脏页和写入缓冲池的速率。默认值为20000。
- **innodb_io_capacity_max**：如果刷新操作过于落后，InnoDB可以超过**innodb_io_capacity**的限制进行刷新，但是不能超过本参数的值。默认值为40000。

#### 临时表导致实例IO高

如果临时目录很大，可能存在慢SQL排序、去重等操作导致创建很大的临时表。临时表写入也会造成I/O增加。

建议进行SQL优化，避免慢SQL

#### 读取冷数据导致实例I/O高

如果SQL查询或修改的数据不在缓冲池（Buffer Pool），则需要从存储中读取，可能会产生大量的I/O吞吐。

根据业务场景重新设计缓存策略，或者升级实例规格。

#### DDL语句导致实例I/O高

DDL语句可能会重建表空间，期间会扫描全表数据、创建索引排序、刷新新表产生的脏页，这些都会导致大量的I/O吞吐。另外一种场景是删除大表造成的I/O抖动。

#### 大事务写Binlog导致实例I/O高

事务只有在提交时才会写Binlog文件，如果存在大事务，例如一条Delete语句删除大量的行，可能会产生几十GB的Binlog文件，Binlog文件刷新到磁盘时，会造成很高的I/O吞吐。

### 活跃线程数高问题

活跃线程数或活跃连接数是衡量MySQL负载状态的关键指标，通常来说一个比较健康的实例活跃连接数应该低于10，高规格和高QPS的实例活跃连接数可能20、30，如果出现几百、上千的活跃连接数，说明出现了SQL堆积和响应变慢，严重时会导致实例停止响应，无法继续处理SQL请求。

#### 排查慢SQL堆积问题

如果通过监控发现活跃线程数升高，首先通过`show processlist;`命令查看是否有慢SQL。如果有很多扫描行数太多的SQL，容易导致活跃连接数升高。

#### 排查表缓存（Table Cache）问题

- 现象

  Table Cache不足时，会导致大量SQL处于`Opening table`状态，在QPS过高或者表很多的场景容易出现。

- 解决方案

  将参数**table_open_cache**（不需要重启实例）和**table_open_cache_instances**（需要重启实例）调大。

#### 排查元数据锁（MDL）问题

- 现象

  出现MDL锁时，会导致大量SQL处于`Waiting for table metadata lock`的状态，在DDL prepare和commit阶段，DDL语句需要获取MDL锁，如果表上有未提交事务或慢SQL，会阻塞DDL操作，DDL操作又会阻塞其他的SQL，最终导致活跃线程数升高。

- 解决方案

  中止未提交事务、慢SQL或正在执行的DDL都可以解决问题。

#### 排查行锁冲突问题

- 现象

  行锁冲突表现为**Innodb_row_lock_waits**和**Innodb_row_lock_time**监控项的指标升高。

可以通过`show engine innodb status;`命令查看是否有大量会话处于`Lock wait`状态，如果有，说明行锁冲突比较严重，需要通过优化热点更新、降低事务大小、及时提交事务等方法避免行锁冲突。

### 自治服务DAS

