# 在prometheus中创建告警规则

把alertmanager运行起来后，也和Prometheus关联了，但alertmanager并不知道要做什么报警，所以我们还需要配置告警规则来设置对哪些数据进行告警。



编辑Prometheus配置文件prometheus.yml,并添加以下内容

```yaml
# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
      - targets:
          - monitor01: 9093
          
  #其中 rule_files 就是用来指定报警规则的
  #默认情况下Prometheus会每分钟对这些告警规则进行计算
  rule_files:
  - "/etc/prometheus/rules/*_rules.yml"
  - "/etc/prometheus/rules/*_alerts.yml"
  ...
  
  -	job_name: 'alertmanager'
    static_configs:
    - targets: ['localhost:9093']
      labels:
        app: alertmanager
```

重启Prometheus服务，成功后，可以从http://192.168.33.10:9090/config查看alerting配置是否生效。

cat node_rules.yml

```yaml
groups:
- name: node_rules #告警规则组名称
  #interval: 15s
  rules:
  - record: instance:node_cpu_usage  
    expr: 100 - avg(irate(node_cpu_seconds_total{mode="idle"}[1m])) by (nodename) * 100
    labels:
      metric_type: CPU_monitor  

  - record: instance:node_1m_load
    expr: node_load1
    labels:
      metric_type: load1m_monitor

  - record: instance:node_mem_usage
    expr: 100 - (node_memory_MemAvailable_bytes)/(node_memory_MemTotal_bytes) * 100
    labels:
      metric_type: Memory_monitor  

  - record: instance:node_root_partition_predit
    expr: round(predict_linear(node_filesystem_free_bytes{device="rootfs",mountpoint="/"}[2h],12*3600)/(1024*1024*1024), 1)
    labels:
      metric_type: root_partition_monitor
```

cat node_alerts.yml

```yaml
groups:
- name: node_alerts #告警组的名称
  rules:
  - alert: cpu_usage_over_threshold #告警规则的名称
    expr: instance:node_cpu_usage > 80 #规则表达式，是用于进行报警规则 PromQL 查询语句
    for: 1m #表示只有当触发条件持续一段时间后才发送告警，在等待期间新产生的告警状态为pending
    labels: #自定义标签，允许用户指定额外的标签列表，把它们附加在告警上
      severity: warning #告警级别
    annotations: #指定了另一组标签，它们不被当做告警实例的身份标识，它们经常用于存储一些额外的信息，用于报警信息的展示之类的
      summary: 主机 {{ $labels.nodename }} 的 CPU使用率持续1分钟超出阈值,当前为 {{humanize $value}} %

  - alert: system_1m_load_over_threshold
    expr: instance:node_1m_load > 20
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: 主机 {{ $labels.nodename }} 的 1分负载超出阈值,当前为 {{humanize $value}}

  - alert: mem_usage_over_threshold
    expr: instance:node_mem_usage > 80
    for: 1m
    annotations:
      summary: 主机 {{ $labels.nodename }} 的 内存 使用率持续1分钟超出阈值,当前为 {{humanize $value}} %

  - alert: root_partition_usage_over_threshold
    expr: instance:node_root_partition_predit < 60
    for: 1m
    annotations:
      summary: 主机 {{ $labels.nodename }} 的 根分区 预计在12小时使用将达到 {{humanize $value}}GB,超出当前可用空间，请及时扩容!
```

在告警规则文件中，我们可以将一组相关的规则设置定义在一个group下。在每一个group中我们可以定义多个告警规则(rule)。

一条告警规则主要由以下几部分组成：

- alert：告警规则的**名称**。
- expr：基于PromQL表达式告警**触发条件**，用于计算是否有时间序列满足该条件。
- for：评估等待时间，可选参数。用于表示只有当**触发条件持续一段时间后才发送告警**。在等待期间新产生告警的状态为pending。
- labels：自定义标签，允许用户指定要附加到告警上的一组附加标签。
- annotations：用于指定一组附加信息，比如用于**描述告警详细信息**的文字等，annotations的内容在告警产生时会一同作为参数发送到Alertmanager。

**模板化**

一般来说，在告警规则文件的annotations中使用`summary`描述告警的概要信息，`description`用于描述告警的详细信息。同时Alertmanager的UI也会根据这两个标签值，显示告警信息。为了让告警信息具有更好的可读性，Prometheus支持模板化label和annotations的中标签的值。

通过`$labels.<labelname>`变量可以访问当前告警实例中指定标签的值。$value则可以获取当前PromQL表达式计算的样本值。

```
# To insert a firing element's label values:
{{ $labels.<labelname> }}
# To insert the numeric expression value of the firing element:
{{ $value }}
```

例如，可以通过模板化优化summary以及description的内容的可读性：

```yaml
groups:
- name: example
  rules:

  # Alert for any instance that is unreachable for >5 minutes.
  - alert: InstanceDown
    expr: up == 0
    for: 5m
    labels:
      severity: page
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes."

  # Alert for any instance that has a median request latency >1s.
  - alert: APIHighRequestLatency
    expr: api_http_request_latencies_second{quantile="0.5"} > 1
    for: 10m
    annotations:
      summary: "High request latency on {{ $labels.instance }}"
      description: "{{ $labels.instance }} has a median request latency above 1s (current value: {{ $value }}s)"
```

**查看告警状态**

可以通过表达式，查询告警实例：

```
ALERTS{alertname="<alert name>", alertstate="pending|firing", <additional alert labels>}
```

样本值为1表示当前告警处于活动状态（pending或者firing），当告警从活动状态转换为非活动状态时，样本值则为0。



**实践环境中的Promethues报警规则** 

```yaml
groups:
- name: 节点监控基础规则(Basic Rules)
  rules:
  - alert: 节点状态宕机
      expr: up == 0
      for: 2m
      labels:
      severity: critical
      status: down
      annotations:
      summary: "来自 {{ $labels.job }} Job,节点 {{$labels.instance}} 状态宕机"
      description: "节点 {{$labels.instance}} 宕机已超过2分钟请进行人工处理。"
  - alert: CPU 使用情况
      expr: 100-(avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by(instance)* 100) > 70
      for: 5m
      labels:
      severity: generality
        status: warning
      annotations:
        summary: "节点 {{$labels.mountpoint}} CPU 使用率过高！"
        description: "节点 {{$labels.mountpoint }} CPU已持续3分钟使用大于 70% (目前使用:{{$value}}%)"
  - alert: Memory 使用情况
      expr: 100 - (node_memory_MemTotal_bytes - node_memory_MemFree_bytes+node_memory_Buffers_bytes+node_memory_Cached_bytes ) / node_memory_MemTotal_bytes * 100 > 80
      for: 1m
      labels:
      severity: generality
        status: warning
      annotations:
        summary: "{{$labels.mountpoint}} 内存使用率过高！"
        description: "{{$labels.mountpoint }} 内存使用大于80%(目前使用:{{$value}}%)"
  - alert: IO 性能情况
      expr: 100 - (avg(irate(node_disk_io_time_seconds_total[5m])) by(instance)* 100) < 30
      for: 2m
      labels:
      severity: generality
        status: warning
      annotations:
        summary: "{{$labels.mountpoint}} 流入磁盘IO使用率过高！"
        description: "{{$labels.mountpoint }} 流入磁盘IO大于70%(目前使用:{{$value}})"
  - alert: Network 接收(receive)情况
      expr: ((sum(rate (node_network_receive_bytes_total{device!~'tap.*|veth.*|br.*|docker.*|virbr*|lo*'}[5m])) by (instance)) / 100) > 102400
      for: 5m
      labels:
      severity: generality
        status: warning
      annotations:
        summary: "{{$labels.mountpoint}} 流入网络带宽过高！"
        description: "{{$labels.mountpoint }} 流入网络带宽持续5分钟高于100M. RX带宽使用率{{$value}}"
  - alert: Network 传输(transmit)情况
      expr: ((sum(rate (node_network_transmit_bytes_total{device!~'tap.*|veth.*|br.*|docker.*|virbr*|lo*'}[5m])) by (instance)) / 100) > 102400
      for: 1m
      labels:
      severity: generality
        status: warning
      annotations:
        summary: "{{$labels.mountpoint}} 流出网络带宽过高！"
        description: "{{$labels.mountpoint }}流出网络带宽持续2分钟高于100M. RX带宽使用率{{$value}}"
  - alert: TCP会话
      expr: node_netstat_Tcp_CurrEstab > 1000
      for: 1m
      labels:
      severity: generality
        status: warning
      annotations:
        summary: "{{$labels.mountpoint}} TCP_ESTABLISHED过高！"
        description: "{{$labels.mountpoint }} TCP_ESTABLISHED大于1000%(目前使用:{{$value}}%)"
  - alert: 磁盘容量
      expr: 100-(node_filesystem_free_bytes{fstype=~"ext4|xfs"}/node_filesystem_size_bytes {fstype=~"ext4|xfs"}*100) > 80
      for: 1m
      labels:
      severity: generality
        status: warning
      annotations:
        summary: "{{$labels.mountpoint}} 磁盘分区使用率过高！"
        description: "{{$labels.mountpoint }} 磁盘分区使用大于80%(目前使用:{{$value}}%)"
# -- 业务监控规则
- name: 业务监控(Business monitoring)
  - alert: APIHighRequestLatency  #对请求延迟中值大于1s的任何实例发出警报。
    expr: api_http_request_latencies_second{quantile="0.5"} > 1
    for: 10m
    labels:
      severity: generality
      status: warning
    annotations:
      summary: "High request latency on {{ $labels.instance }}"
      description: "{{ $labels.instance }} has a median request latency above 1s (current value: {{ $value }}s)"

# -- 数据库监控规则
- name: RedisAlert
  rules:
  - alert: Redis 内存情况
    expr: 100 * (redis_memory_used_bytes / redis_config_maxmemory) > 90
    for: 1m
    labels:
      severity: generality
      status: warning
    annotations:
      summary: "Redis {{ $labels.instance }} memory userd over 90"
      description: "Redis memory used over 90 duration above 1m"

# -- 队列监控规则
- name: KafkaAlert
  rules:
  - alert: kafka 消费者(Consumer)group_lag情况
    expr: sum(kafka_consumergroup_lag{instance != "kafka-dev" }) by (instance, consumergroup,topic) > 500
    for: 5m
    labels:
      severity: generality
      status: warning
    annotations:
      summary: "kafka {{ $labels.topic }} 消费延迟报警"
      description: "kafka 消费延迟有 {{ $value}} 队列数"
```

