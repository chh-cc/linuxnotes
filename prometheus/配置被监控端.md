# 配置被监控端

[Configuration | Prometheus](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)

检查配置文件是否正确：`./promtool check config prometheus.yml`

重新加载配置：`kill -hup 进程id`

## 全局配置文件

```yaml
vim prometheus.yml
global:
	scrape_interval:     15s	#每隔15秒采集一次数据，默认1m
	evaluation_interval: 15s	#记录规则和报警规则的执行间隔（频率），默认1m
	scrape_timeout: 15s	#采集数据的超时时间，该值不能大于scrape_interval的值，默认10s。

#告警规则（比如cpu超过多少发送告警）
rule_files:
    ...
    
#配置被监控端，称为target，每个target用job_name分组管理，又分静态配置和服务发现
scrape_configs:
    ...
    
#告警配置
alerting:
    ...
```

## scrape_configs

```yaml
#采集对象的作业名称
job_name: <job_name>

#默认继承全局配置global，在这指定局部配置会覆盖全局配置
[ scrape_interval: 15s ]
[ scrape_timeout: 15s ]

#指标路径
[ metrics_path: /metrics ]
#标签
[ honor_labels: <boolean> | default = false ]

#目标拉取协议
[ scheme: <scheme> | default = http ]

#参数
params:
  [ <string>: [<string>, ...] ]

#基础认证
basic_auth:
  [ username: <string> ]
  [ password: <secret> ]
  [ password_file: <string> ]
tls_config:
  [ <tls_config> ]
[ proxy_url: <string> ]

#设置多种服务发现，最常见有以下两种方式
## 基于文件的服务发现提供了一种更通用的方法来配置静态目标，并充当插入自定义服务发现机制的接口(文件可以YAML或JSON格式提供,格式样例看下面的tips)
file_sd_configs:
  - files:
    - my/path/tg_*.json
    [ refresh_interval: <duration> | default = 5m ] # 该静态文件刷新时间间隔
# 基于kubernetes的服务发现,允许从 Kubernetes REST API 拉取集群pod相关信息并时刻保持同步。
kubernetes_sd_configs:
  [ - <kubernetes_sd_config> ... ]
...

#指定静态目标
static_configs:
  - target: ['localhost:9090','localhost:9191']
    labels:
        [ <labelname>: <labelvalue> ... ]
        
#重新标记  
relabel_configs:
  ...
  
metric_relabel_configs:
  ...
  
[ sample_limit: <int> | default = 0 ]
```

## relabel_configs

### 标签的作用

Prometheus中存储的数据为时间序列，是由Metric的名字和一系列的标签(键值对)唯一标识的, **不同的标签代表不同的时间序列**，即**通过指定标签查询指定数据** 

指标+标签实现了查询条件的作用，可以指定不同的标签过滤不同的数据

### Metadata标签

在Prometheus所有的Target实例中，都包含一些默认的Metadata标签信息。可以通过Prometheus UI的Targets页面中查看这些实例的Metadata标签的内容：

![image-20220707224547619](assets/image-20220707224547619.png)

- \__address__：当前Target实例的访问地址<host>:<port>

- \__scheme__：采集目标服务访问地址的HTTP Scheme，HTTP或者HTTPS

- \__metrics_path__：采集目标服务访问地址的访问路径

上面这些标签将会告诉Prometheus如何从该Target实例中获取监控数据。

**使用promql是查询不到这些标签的，因为这些标签只是普罗米修斯内部去使用的，不会存储在时序数据库供我们查询**

### 自定义标签

给样本增加一个自定义标签

```yaml
- job_name: 'prometheus'
  static_configs:
  - target: ['localhost:9090']
    labels:
      idc: bj  
```

### 重新标记标签

允许在采集之前对任何目标及其标签进行修改，**重新标记目的：为了更好的标识监控指标。**

重新标签的意义：

- 根据已有的标签生成新标签
- 删除标签
- 过滤采集的Target
- 添加新标签





relabel规则组成：

```yaml
relabel_configs:
  #源标签，对哪些源标签进行relabel
  [ source_labels: '[' <labelname> [, ...] ']' ]
  #分隔符，用于在连接源标签source_labels时分割它们
  [ separator: <string> | default = ; ]
  #目标标签，relabel后的标签名
  [ target_label: <labelname> ]
  #正则表达式，用于匹配串联的源标签
  [ regex: <regex> | default = (.*) ]
  #如果正则表达式匹配，则对其执行正则表达式替换的替换值
  [ replacement: <string> | default = $1 ]
  #执行的 relabeling 动作，可选值包括 replace、keep、drop、hashmod、labelmap、labeldrop 或者 labelkeep，默认值为 replace
  [ action: <relabel_action> | default = replace ]
```

relabel的action动作：

- replace：默认，通过regex匹配source_label的值，使用replacement来引用表达式匹配的分组，分组使用$1,$2...引用（正则匹配，提取字段重新创建新标签，注意这里是创建新的标签）
-  keep：删除regex与连接不匹配的目标 source_labels ， **keep drop就是让普罗米修斯采集和不采集哪些目标**
- drop：删除regex与连接匹配的目标 source_labels
- labeldrop：删除regex匹配的标签
- labelkeep：删除regex不匹配的标签
- labelmap：匹配regex所有标签名称，并将捕获的内容分组，用第一个分组内容作为新的标签名（使用正则提取出多个字段，使用匹配到的作为新标签名，但是标签的内容不会改变，相对于对原有标签换了个名字）



设置或替换源标签：

```yaml
#把地址http://node-ip:10250/metrics替换成http://node-ip:9100/metrics
    - job_name: 'kubernetes-sd-node-exporter'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: replace
        source_labels: [__address__] #要替换的源标签
        regex: '(.*):10250' #正则匹配ip地址
        replacement: '${1}:9100' #使用第一个捕获组作为replacement
        target_label: __address__

这里我们替换的源标签为__address__，
然后通过正则表达式(.*):10250匹配，这里只有一个捕获组$1:端口，
然后在 replacement 字符串中我们保留第一个捕获组 $1，然后将端口更改为9100，
把经过正则表达式替换的 replacement 字符串作为 target_label 标签的新值存储起来
```



保留或丢弃对象：

Relabeling 另一个常见的用例就是过滤有标签的对象，keep 或 drop 这两个动作可以来完成，使用这两个操作，可以帮助我们完成如下的一些操作：

- 来自服务发现的哪些目标应该被抓取
- 从目标中抓取哪些指定的序列样本，或将其发送到远程存储
- 哪些报警要发送到 Alertmanager

```yaml
- job_name: 'kubernetes-service-endpoints'
  kubernetes_sd_configs:
  - role: endpoint
  relabel_configs:
  - action: keep
    source_labels: [__meta_kubernetes_service_annotation_example_io_should_be_scraped]
    regex: true

Kubernetes 服务发现机制下面会将 labels 标签与 annotation 作为元信息输出到 Prometheus，这些元信息都包含 __meta_ 前缀，这里我们的配置就是保留具有 example.io/should_be_scraped 这个 annotation 标签，且值为 true 的目标。
```

## metric_relabel_configs

Prometheus 从数据源拉取数据后，会对原始数据进行编辑

其中 `metric_relabel_configs`是 Prometheus 在保存数据前的最后一步标签重新编辑（relabel_configs）。所以，哪怕你将 `metric_relabel_configs`模块放在 `job_name`模块的最前端，Prometheus 解析编辑文件后，也会将 `metric_relabel_configs`放在最后。

`metric_relabel_configs` 模块和 `relabel_config` 模块很相似。`metric_relabel_configs`一个很常用的用途：**将监控不需要的数据，直接丢掉，不在Prometheus 中保存。**

### 删除不需要的标签

prometheus 默认会将所有拉取到的 metrics 都写入自己的存储中。如果某些 metrics 对我们并没有太多意义，可以设置直接丢掉，减少磁盘空间的浪费。`‘node_netstat_Icmp_OutMsgs’` 指标数据。

```yaml
  metric_relabel_configs:
   - source_labels: [ __name__ ]
     regex: 'node_netstat_Icmp_OutMsgs'
     action: drop
```

### 修改指标中的label

如果相同含义的label，名称却不相同；对query的编写就很困难了。正确的解决思路应该是在 Prometheus 拉取数据后，保存数据前；将 label 的名称进行重写；保证相同含义的label 有相同的名称。

将指定` job_name `中，所有的` metrics `中含有名为“pod”和“container”名称的` label `分别拷贝到名为“pod_name”，“container_name”的label中。

```yaml

metric_relabel_configs:
  - source_labels: [pod]
    separator: ;
    regex: (.+)
    target_label: pod_name
    replacement: $1
    action: replace
  - source_labels: [container]
    separator: ;
    regex: (.+)
    target_label: container_name
    replacement: $1
    action: replace
```

