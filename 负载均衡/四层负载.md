# 四层负载

## 一、集群概念

集群是一组相互独立的、通过高速网络互联的计算机，它们构成了一个组，并以单一系统的模式加以管理。一个客户与集群相互作用时，集群像是一个独立的服务器。

集群组成后，可以利用多个计算机和组合进行海量请求处理（**负载均衡**），从而获得很**高的处理效率**，也可以用多个计算机**做备份（高可用）**，使得任何一个机器坏了整个系统还是能正常运行。集群在目前互联网公司是必备的技术，极大提高互联网业务的可用性和可缩放性。

## 二、负载均衡集群



使每个节点都可以承担一定的处理负载，并且可以实现处理负载在节点之间的动态分配，以实现负载均衡。

负载通常包括应用程序处理负载和网络流量负载。

**负载均衡技术类型：基于 4 层负载均衡技术和基于 7 层负载均衡技术**

**负载均衡实现方式：硬件负载均衡设备或者软件负载均衡**

**硬件负载均衡产品：F5 BIG-IP 、Citrix Netscaler  、深信服 、Array 、Radware**

**软件负载均衡产品： LVS（Linux Virtual Server）、 Haproxy、Nginx、Ats（apache traffic server）**

### 1、四层负载均衡

基于IP+端口的负载均衡

1. 在三层负载均衡的基础上，通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，**对需要处理的流量进行NAT处理**，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。
2. 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。
3. 对应的负载均衡器称为四层交换机（L4 switch），主要分析IP层及TCP/UDP层，实现四层负载均衡。此种负载均衡器**不支持应用协议**（如HTTP/FTP/MySQL等等）
4. 实现四层负载均衡的软件有：
   - F5：硬件负载均衡器，功能很好，但是成本很高。
   - lvs：重量级的四层负载软件
   - nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活
   - haproxy：模拟四层转发，较灵活

### 2、七层的负载均衡

基于虚拟的URL或主机IP的负载均衡

1. 在四层负载均衡的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，**除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡**。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。
2. 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个**代理服务器**。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。
3. 对应的负载均衡器称为七层交换机（L7 switch），除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息，实现七层负载均衡。此种负载均衡器能理解应用协议。
4. 实现七层负载均衡的软件有：
   - haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；
   - nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；
   - apache：功能较差
   - Mysql proxy：功能尚可。

### 3、四层负载与七层负载的区别

|          | 四层负载均衡（layer 4） | 七层负载均衡（layer 7）                          |
| -------- | ----------------------- | ------------------------------------------------ |
| 基于     | 基于IP  Port            | URL                                              |
| 类似于   | 路由器                  | 代理服务器                                       |
| 握手次数 | 1 次                    | 2 次                                             |
| 复杂度   | 低                      | 高                                               |
| 性能     | 高；无需解析内容        | 中；需要算法识别 URL，Cookie 和 HTTP head 等信息 |
| 安全性   | 低，无法识别 DDoS等攻击 | 高， 可以防御SYN cookie以SYN flood等             |
| 额外功能 | 无                      | 会话保持，图片压缩，防盗链等                     |

## 三、LVS 实现四层负载均衡

### 1、LVS 介绍

现在LVS已经是 Linux标准内核的一部分，

##### 1.优势

**高并发连接**：LVS基于内核网络层面工作，有超强的承载能力和并发处理能力。单台LVS负载均衡器，可支持上万并发连接。

**稳定性强：**是工作在网络4层之上仅作分发之用，这个特点也决定了它在负载均衡软件里的性能最强，稳定性最好，对内存和cpu资源消耗极低。

**成本低廉：**硬件负载均衡器少则十几万，多则几十万上百万，LVS只需一台服务器和就能免费部署使用，性价比极高。

**配置简单：**LVS配置非常简单，仅需几行命令即可完成配置，也可写成脚本进行管理。

**支持多种算法：**支持多种论调算法，可根据业务场景灵活调配进行使用

**支持多种工作模型：**可根据业务场景，使用不同的工作模式来解决生产环境请求处理问题。

应用范围广：因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、DNS、ftp服务等等

##### 2.不足

工作在4层，不支持7层规则修改，机制过于庞大，不适合小规模应用

##### 3.核心组件

LVS的管理工具和内核模块 ipvsadm/ipvs

ipvsadm：用户空间的命令行工具，用于管理集群服务及集群服务上的RS等；

ipvs：工作于内核上的netfilter INPUT钩子之上的程序，可根据用户定义的集群实现请求转发；

##### 4.专业术语

**VS**：Virtual Server            #虚拟服务

**Director, Balancer**          #负载均衡器、分发器

**RS**：Real Server                #后端请求处理服务器 

**CIP**: Client IP                      #用户端IP

**VIP**：Director Virtual IP   #负载均衡器虚拟IP

**DIP**：Director IP               #负载均衡器IP

**RIP**：Real Server IP         #后端请求处理服务器

### 2、LVS工作内核模型及工作模式

1、当客户端的请求到达负载均衡器的内核空间时，首先会到达 PREROUTING 链。

2、当内核发现请求数据包的目的地址是本机时，将数据包送往 INPUT 链。

3、LVS由用户空间的ipvsadm和内核空间的IPVS组成，**ipvsadm用来定义规则**，**IPVS利用ipvsadm定义的规则工作**，IPVS工作在INPUT链上,当数据包到达INPUT链时，首先会被IPVS检查，如果数据包里面的目的地址及端口没有在规则里面，那么这条数据包将被放行至用户空间。

4、**如果数据包里面的目的地址及端口在规则里面，那么这条数据报文将被修改目的地址为事先定义好的后端服务器，并送往POSTROUTING链**。

5、最后经由POSTROUTING链发往后端服务器。

![](https://gitee.com/c_honghui/picture/raw/master/img/20210223110632.png)

### 3、LVS负载均衡四种工作模式

#### 1、NAT工作模式



工作流程：

1、 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的 PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP

2、 PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链

3、IPVS比对数据包请求的服务是否为集群服务，若是，修改数据包的目标IP地址为后端服务器IP，然后将数据包发至POSTROUTING链。 此时报文的源IP为CIP，目标IP为RIP

4、POSTROUTING链通过选路，将数据包发送给Real Server

5、Real Server比对发现目标为自己的IP，开始构建响应报文发回给Director Server。 此时报文的源IP为RIP，目标IP为CIP

6、Director Server 把RS来到响应包，通过FORWORD 转发给client 在响应客户端前，此时会将源IP地址修改为自己的VIP地址，然后响应给客户端。 此时报文的源IP为VIP，目标IP为CIP

图解：

![](https://gitee.com/c_honghui/picture/raw/master/img/20210223112707.png)

![](https://gitee.com/c_honghui/picture/raw/master/img/20210223113012.png)

#### 2、DR 工作模式



工作流程：

1、 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP

2、 PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链

3、 IPVS比对数据包请求的服务是否为集群服务，若是，将请求报文中的**源MAC地址修改为DIP的MAC地址，将目标MAC地址修改RIP的MAC地址**，然后将数据包发至POSTROUTING链。 此时的源IP和目的IP均未修改，仅修改了源MAC地址为DIP的MAC地址，目标MAC地址为RIP的MAC地址

4、 由于**DS和RS在同一个网络中，所以是通过二层，数据链路层来传输**。POSTROUTING链检查目标MAC地址为RIP的MAC地址，那么此时数据包将会发至Real Server。

5、 RS发现请求报文的MAC地址是自己的MAC地址，就接收此报文。处理完成之后，将响应报文通过lo接口传送给eth0网卡然后向外发出。 此时的**源IP地址为VIP，目标IP为CIP**

6、 响应报文最终送达至客户端 

图解：

![](https://gitee.com/c_honghui/picture/raw/master/img/20210223114235.png)

![](https://gitee.com/c_honghui/picture/raw/master/img/20210223115108.png)



#### 3、LVS TUN 工作模式

###### 

工作流程：

1、 客户端将请求发往前端的负载均衡器，请求报文源地址是CIP，目标地址为VIP。

2、 负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将在客户端请求报文的首部再封装一层IP报文,将源地址改为DIP，目标地址改为RIP,并将此包发送给RS。

3、 RS收到请求报文后，会首先拆开第一层封装,然后发现里面还有一层IP首部的目标地址是自己lo接口上的VIP，所以会处理次请求报文，并将响应报文**通过lo接口送给eth0网卡直接发送给客户端**。注意：需要设置lo接口的VIP不能在共网上出现 

图解：

![](https://gitee.com/c_honghui/picture/raw/master/img/20210223115738.png)

#### 4、LVS full-nat 工作模式

lvs-fullnat（双向转换）

通过请求报文的源地址为DIP，目标为RIP来实现转发：对于响应报文而言，修改源地址为VIP，目标地址为CIP来实现转发：

​          CIP --> DIP           VIP --> RIP

架构特点：这是一种对nat模型的改进，是一个扩展，使得RS与Director可以处于不同网络。

（1）RIP，DIP可以使用私有地址；

（2）RIP和DIP可以不再同一个网络中，且RIP的网关未必需要指向DIP；

（3）支持端口映射；

（4）RS的OS可以使用任意类型；

（5）请求报文经由Director，响应报文也经由Director

![](https://gitee.com/c_honghui/picture/raw/master/img/20210223125159.png)

#### 5、四者的区别

| 机器名称   | IP配置                             | 服务角色   | 备注                               |
| ---------- | ---------------------------------- | ---------- | ---------------------------------- |
| lvs-server | VIP:172.16.100.1 DIP:192.168.100.1 | 负载均衡器 | 开启路由功能（VIP桥接、DIP仅主机） |
| rs01       | RIP：192.168.100.2                 | 后端服务器 | 网关指向DIP（仅主机）              |
| rs02       | RIP：192.168.100.3                 | 后端服务器 | 网关指向DIP（仅主机）              |
| rs03       | RIP：192.168.100.4                 | 后端服务器 | 网关指向DIP（仅主机）              |

lvs-nat与lvs-fullnat：请求和响应报文都经由Director

   　　lvs-nat：RIP的网关要指向DIP

  　　 lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信

lvs-dr与lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client

  　　 lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发

  　　 lvs-tun：通过在原IP报文外封装新IP头实现转发，支持远距离通信 

### 4、LVS ipvsadm 命令的使用

安装 lvs 管理软件

```shell
[root@qfedu.com ~]# yum -y install ipvsadm
```

命令选项

```shell
-A --add-service #在服务器列表中新添加一条新的虚拟服务器记录
-t #表示为tcp服务
-u #表示为udp服务
-s --scheduler #使用的调度算法， rr | wrr | lc | wlc | lblb | lblcr | dh | sh | sed | nq 默认调度算法是 wlc
例：ipvsadm -A -t 192.168.1.2:80 -s wrr

-a --add-server  #在服务器表中添加一条新的真实主机记录
-t --tcp-service #说明虚拟服务器提供tcp服务
-u --udp-service #说明虚拟服务器提供udp服务
-r --real-server #真实服务器地址
-m --masquerading #指定LVS工作模式为NAT模式
-w --weight #真实服务器的权值
-g --gatewaying #指定LVS工作模式为直接路由器模式（也是LVS默认的模式）
-i --ip #指定LVS的工作模式为隧道模式
-p #会话保持时间，定义流量被转到同一个realserver的会话存留时间
例：ipvsadm -a -t 192.168.1.2:80 -r 192.168.2.10:80 -m -w 1

-E -edit-service #编辑内核虚拟服务器表中的一条虚拟服务器记录。
-D -delete-service #删除内核虚拟服务器表中的一条虚拟服务器记录。
-C -clear #清除内核虚拟服务器表中的所有记录。
-R -restore #恢复虚拟服务器规则
-S -save #保存虚拟服务器规则，输出为-R 选项可读的格式
-e -edit-server #编辑一条虚拟服务器记录中的某条真实服务器记录
-d -delete-server #删除一条虚拟服务器记录中的某条真实服务器记录
-L|-l –list #显示内核虚拟服务器表

--numeric, -n：#以数字形式输出地址和端口号
--exact： #扩展信息，精确值 
--connection，-c： #当前IPVS连接输出
--stats： #统计信息
--rate ： #输出速率信息

参数也可以从/proc/net/ip_vs*映射文件中查看
-Z –zero #虚拟服务表计数器清零（清空当前的连接数量等）
```

### 5、LVS的调度算法

##### 1、静态算法（4种）

只根据算法进行调度 而不考虑后端服务器的实际连接情况和负载情况

**1、RR**：轮叫调度（Round Robin）

　 调度器通过”轮叫”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载｡

**2、WRR**：加权轮叫（Weight RR）

　 调度器通过“加权轮叫”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器处理更多的访问流量。调度器可以自动问询真实服务器的负载情况,并动态地调整其权值。

**3、DH**：目标地址散列调度（Destination Hash ）

　 根据请求的目标IP地址，作为散列键(HashKey)从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。

**4、SH**：源地址 hash（Source Hash）

　 源地址散列”调度算法根据请求的源IP地址，作为散列键(HashKey)从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空｡

##### 2、动态算法（6种）

前端的调度器会根据后端真实服务器的实际连接情况来分配请求

**1、LC**：最少链接（Least Connections）

　 调度器通过”最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用”最小连接”调度算法可以较好地均衡负载。

**2、WLC**：加权最少连接(默认采用的就是这种)（Weighted Least Connections）

　 在集群系统中的服务器性能差异较大的情况下，调度器采用“加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载｡调度器可以自动问询真实服务器的负载情况,并动态地调整其权值。

## **四、LVS DR 模式搭建**(阿里云服务器无法做LVS，但云产品是采用LVS技术)

**三台服务器A、B、C：**

#### A: load balancer

内网网卡：192.168.31.128，网关保持不变（192.168.31.2）

外网网卡：192.168.229.128，先不用理会，这里用不到

```shell
[root@a.qfedu.com ~]# setenforce 0 # 关闭selinux
[root@a.qfedu.com ~]# systemctl stop firewalld # 停止firewalld
[root@a.qfedu.com ~]# systemctl disable firewalld # 关闭firewalld
[root@a.qfedu.com ~]# yum install -y iptables-services # 安装iptables
[root@a.qfedu.com ~]# systemctl enable iptables # 添加iptables服务
[root@a.qfedu.com ~]# systemctl start iptables.service # 启动iptables服务
[root@a.qfedu.com ~]# iptables -F # 清空iptables规则
[root@a.qfedu.com ~]# service iptables save # 保存空规则
[root@a.qfedu.com ~]# yum -y install ipvsadm net-tools
```

1、创建 LVS 的 DR 规则脚本

```shell
写入以下内容：
[root@qfedu.com ~]# vim /usr/local/sbin/lvs_dr.sh
echo 1 > /proc/sys/net/ipv4/ip_forward # 临时打开路由转发
ipv=/usr/sbin/ipvsadm # 设置ipvsadm变量
vip=192.168.31.200 # 设置公用ip变量（virtual ip）
rs1=192.168.31.129 # 设置real server1ip的变量
rs2=192.168.31.130 # 设置real server2ip的变量
ifdown eth0 # 关闭网卡
ifup eth0 # 启动网卡，目的时清空临时设定的ip，避免重复设定
ifconfig eth0:2 $vip broadcast $vip netmask 255.255.255.255 up # 绑定vip到虚拟网卡eth0:2上
route add -host $vip dev eth0:2 # 为eth0:2网卡添加网关
$ipv -C # 清空规则
$ipv -A -t $vip:80 -s wrr # -A指定转发模式，-t指定director ip，-s指定调度算法 wrr加权轮询调度
$ipv -a -t $vip:80 -r $rs1:80 -g -w 1
# 指定转发规则，-a指定转发规则，-t指定调度器(director)ip，-r指定real server IP，-g指定转发模式为DR(gateway) -w指定权重
$ipv -a -t $vip:80 -r $rs2:80 -g -w 1
# 指定转发规则，-a指定转发规则，-t指定调度器(director)ip，-r指定real server IP，-g指定转发模式为DR(gateway) -w指定权重

例子：
#!/bin/bash
echo 1 > /proc/sys/net/ipv4/ip_forward
ipv=/usr/sbin/ipvsadm
vip=192.168.152.200
rs1=192.168.152.132
rs2=192.168.152.133
ifdown eth0
ifup eth0
ifconfig eth0:2 $vip broadcast $vip netmask 255.255.255.255 up
route add -host $vip dev eth0:2
$ipv -C
$ipv -A -t $vip:80 -s wrr
$ipv -a -t $vip:80 -r $rs1:80 -g -w 1
$ipv -a -t $vip:80 -r $rs2:80 -g -w 1
```

2、给脚本设权

```shell
[root@a.qfedu.com ~]# chmod 755 /usr/local/sbin/lvs_dr.sh
```

3、执行脚本

```shell
[root@a.qfedu.com ~]# sh /usr/local/sbin/lvs_dr.sh
```

4、查看路由上的 vip

```shell
[root@a.qfedu.com ~]# route -n
```

5、查看网卡 eth0 上的 vip

```shell
[root@a.qfedu.com ~]# ip addr
```

#### B: real server 

（web服务器） 内网网卡：192.168.31.129 网关改回129.168.31.2

安装nginx，并启动，在默认主页里写入，real server 1 关闭selinux，清空防火墙规则

1、创建转发脚本

```shell
[root@b.qfedu.com ~]# yum -y install net-tools

[root@b.qfedu.com ~]# vim /usr/local/sbin/lvs_rs.sh

写入以下内容：
#/bin/bash
vip=192.168.31.200
#把vip绑定在lo上，是为了实现rs直接把结果返回给客户端
ifdown lo
ifup lo
ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 up绑定vip到虚拟网卡lo:0上
route add -host $vip lo:0为lo:0网卡添加网关
#以下操作为更改arp内核参数，目的是为了让rs顺利发送mac地址给客户端
echo "1" >/proc/sys/net/ipv4/conf/lo/arp_ignore
echo "2" >/proc/sys/net/ipv4/conf/lo/arp_announce
echo "1" >/proc/sys/net/ipv4/conf/all/arp_ignore
echo "2" >/proc/sys/net/ipv4/conf/all/arp_announce

arp_ignore:定义对目标地址为本地IP的ARP询问不同的应答模式0 
0 - (默认值): 回应任何网络接口上对任何本地IP地址的arp查询请求 
1 - 只回答目标IP地址是来访网络接口本地地址的ARP查询请求 
2 -只回答目标IP地址是来访网络接口本地地址的ARP查询请求,且来访IP必须在该网络接口的子网段内 
3 - 不回应该网络界面的arp请求，而只对设置的唯一和连接地址做出回应 
4-7 - 保留未使用 
8 -不回应所有（本地地址）的arp查询

arp_announce:对网络接口上，本地IP地址的发出的，ARP回应，作出相应级别的限制: 确定不同程度的限制,宣布对来自本地源IP地址发出Arp请求的接口 
0 - (默认) 在任意网络接口（eth0,eth1，lo）上的任何本地地址 
1 -尽量避免不在该网络接口子网段的本地地址做出arp回应. 当发起ARP请求的源IP地址是被设置应该经由路由达到此网络接口的时候很有用.此时会检查来访IP是否为所有接口上的子网段内ip之一.如果改来访IP不属于各个网络接口上的子网段内,那么将采用级别2的方式来进行处理. 
2 - 对查询目标使用最适当的本地地址.在此模式下将忽略这个IP数据包的源地址并尝试选择与能与该地址通信的本地地址.首要是选择所有的网络接口的子网中外出访问子网中包含该目标IP地址的本地地址. 如果没有合适的地址被发现,将选择当前的发送网络接口或其他的有可能接受到该ARP回应的网络接口来进行发送.

关于对arp_announce 理解的一点补充
其实就是路由器的问题，因为路由器一般是动态学习ARP包的（一般动态配置DHCP的话），当内网的机器要发送一个到外部的ip包，那么它就会请求 路由器的Mac地址，发送一个arp请求，这个arp请求里面包括了自己的ip地址和Mac地址，而linux默认是使用ip的源ip地址作为arp里面 的源ip地址，而不是使用发送设备上面的 ，这样在lvs这样的架构下，所有发送包都是同一个VIP地址，那么arp请求就会包括VIP地址和设备 Mac，而路由器收到这个arp请求就会更新自己的arp缓存，这样就会造成ip欺骗了，VIP被抢夺，所以就会有问题。 
arp缓存为什么会更新了，什么时候会更新呢，为了减少arp请求的次数，当主机接收到询问自己的arp请求的时候，就会把源ip和源Mac放入自 己的arp表里面，方便接下来的通讯。如果收到不是询问自己的包（arp是广播的，所有人都收到），就会丢掉，这样不会造成arp表里面无用数据太多导致 有用的记录被删除。  
在设置参数的时候将arp_ignore 设置为1，意味着当别人的arp请求过来的时候，如果接收的设备上面没有这个ip，就不做出响应，默认是0，只要这台机器上面任何一个设备上面有这个ip，就响应arp请求，并发送mac地址

例子：
#/bin/bash
vip=192.168.152.200
ifdown lo
ifup lo
ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 up
route add -host $vip lo:0
echo "1" >/proc/sys/net/ipv4/conf/lo/arp_ignore
echo "2" >/proc/sys/net/ipv4/conf/lo/arp_announce
echo "1" >/proc/sys/net/ipv4/conf/all/arp_ignore
echo "2" >/proc/sys/net/ipv4/conf/all/arp_announce
```

2、给脚本设权

```shell
[root@b.qfedu.com ~]# chmod 755 /usr/local/sbin/lvs_rs.sh
```

3、执行脚本

```shell
[root@b.qfedu.com ~]# sh /usr/local/sbin/lvs_rs.sh
```

4、查看路由上的 vip

```shell
[root@b.qfedu.com ~]# route -n
```

5、查看网卡 lo 上的 vip

```shell
[root@b.qfedu.com ~]# ip addr
```

#### C: real server 

（web服务器） 内网网卡：192.168.31.130 网关改回129.168.31.2

安装nginx，并启动，在默认主页里写入，real server 2 关闭selinux，清空防火墙规则

1、创建转发脚本

```shell
[root@c.qfedu.com ~]# yum -y install net-tools

[root@c.qfedu.com ~]# vim /usr/local/sbin/lvs_rs.sh

写入以下内容：
#/bin/bash
vip=192.168.31.200
#把vip绑定在lo上，是为了实现rs直接把结果返回给客户端
ifdown lo
ifup lo
ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 up绑定vip到虚拟网卡lo:0上
route add -host $vip lo:0为lo:0网卡添加网关
#以下操作为更改arp内核参数，目的是为了让rs顺利发送mac地址给客户端
echo "1" >/proc/sys/net/ipv4/conf/lo/arp_ignore
echo "2" >/proc/sys/net/ipv4/conf/lo/arp_announce
echo "1" >/proc/sys/net/ipv4/conf/all/arp_ignore
echo "2" >/proc/sys/net/ipv4/conf/all/arp_announce

arp_ignore:定义对目标地址为本地IP的ARP询问不同的应答模式0 
0 - (默认值): 回应任何网络接口上对任何本地IP地址的arp查询请求 
1 - 只回答目标IP地址是来访网络接口本地地址的ARP查询请求 
2 -只回答目标IP地址是来访网络接口本地地址的ARP查询请求,且来访IP必须在该网络接口的子网段内 
3 - 不回应该网络界面的arp请求，而只对设置的唯一和连接地址做出回应 
4-7 - 保留未使用 
8 -不回应所有（本地地址）的arp查询

arp_announce:对网络接口上，本地IP地址的发出的，ARP回应，作出相应级别的限制: 确定不同程度的限制,宣布对来自本地源IP地址发出Arp请求的接口 
0 - (默认) 在任意网络接口（eth0,eth1，lo）上的任何本地地址 
1 -尽量避免不在该网络接口子网段的本地地址做出arp回应. 当发起ARP请求的源IP地址是被设置应该经由路由达到此网络接口的时候很有用.此时会检查来访IP是否为所有接口上的子网段内ip之一.如果改来访IP不属于各个网络接口上的子网段内,那么将采用级别2的方式来进行处理. 
2 - 对查询目标使用最适当的本地地址.在此模式下将忽略这个IP数据包的源地址并尝试选择与能与该地址通信的本地地址.首要是选择所有的网络接口的子网中外出访问子网中包含该目标IP地址的本地地址. 如果没有合适的地址被发现,将选择当前的发送网络接口或其他的有可能接受到该ARP回应的网络接口来进行发送.

关于对arp_announce 理解的一点补充
其实就是路由器的问题，因为路由器一般是动态学习ARP包的（一般动态配置DHCP的话），当内网的机器要发送一个到外部的ip包，那么它就会请求 路由器的Mac地址，发送一个arp请求，这个arp请求里面包括了自己的ip地址和Mac地址，而linux默认是使用ip的源ip地址作为arp里面 的源ip地址，而不是使用发送设备上面的 ，这样在lvs这样的架构下，所有发送包都是同一个VIP地址，那么arp请求就会包括VIP地址和设备 Mac，而路由器收到这个arp请求就会更新自己的arp缓存，这样就会造成ip欺骗了，VIP被抢夺，所以就会有问题。 
arp缓存为什么会更新了，什么时候会更新呢，为了减少arp请求的次数，当主机接收到询问自己的arp请求的时候，就会把源ip和源Mac放入自 己的arp表里面，方便接下来的通讯。如果收到不是询问自己的包（arp是广播的，所有人都收到），就会丢掉，这样不会造成arp表里面无用数据太多导致 有用的记录被删除。  
在设置参数的时候将arp_ignore 设置为1，意味着当别人的arp请求过来的时候，如果接收的设备上面没有这个ip，就不做出响应，默认是0，只要这台机器上面任何一个设备上面有这个ip，就响应arp请求，并发送mac地址

例子：
#/bin/bash
vip=192.168.152.200
ifdown lo
ifup lo
ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 up
route add -host $vip lo:0
echo "1" >/proc/sys/net/ipv4/conf/lo/arp_ignore
echo "2" >/proc/sys/net/ipv4/conf/lo/arp_announce
echo "1" >/proc/sys/net/ipv4/conf/all/arp_ignore
echo "2" >/proc/sys/net/ipv4/conf/all/arp_announce
```

2、给脚本设权

```shell
[root@c.qfedu.com ~]# chmod 755 /usr/local/sbin/lvs_rs.sh
```

3、执行脚本

```shell
[root@c.qfedu.com ~]# sh /usr/local/sbin/lvs_rs.sh
```

4、查看路由上的 vip

```shell
[root@c.qfedu.com ~]# route -n
```

5、查看网卡 lo 上的 vip

```shell
[root@c.qfedu.com ~]# ip addr
```

#### 测试

浏览器里访问192.168.31.200，（vip:vitrual ip）多刷新几次看结果，服务器的切换。

浏览器上因为有本地缓存的原因，虽已经设定了登陆保持时限为1秒，但每次刷新都会保持在real server 2主机上。可以在调度机里用 curl 192.168.31.200 测试访问，调度算法采用rr，效果更明显。

1、用 ipvsadm 命令查看转发规则

```shell
[root@a.qfedu.com  ~]# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
-> RemoteAddress:Port Forward Weight ActiveConn InActConn
TCP 192.168.31.200:80 wrr
-> 192.168.31.129:80 Route 1 0 4
-> 192.168.31.130:80 Route 1 0 5

# ActiveConn是活动连接数,也就是tcp连接状态的ESTABLISHED;InActConn是指除了ESTABLISHED以外的,所有的其它状态的tcp连接
```

2、查看 iptables nat 链的转发规则

```shell
[root@a.qfedu.com  ~]# iptables -t nat -nvL
Chain PREROUTING (policy ACCEPT 89 packets, 13284 bytes)
pkts bytes target prot opt in out source destination

Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
pkts bytes target prot opt in out source destination

Chain OUTPUT (policy ACCEPT 40 packets, 4692 bytes)
pkts bytes target prot opt in out source destination

Chain POSTROUTING (policy ACCEPT 7 packets, 2296 bytes)
pkts bytes target prot opt in out source destination
48 3648 MASQUERADE all -- * * 192.168.31.0/24 0.0.0.0/0
```

